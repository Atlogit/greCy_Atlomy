{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11315,
     "status": "ok",
     "timestamp": 1655285213416,
     "user": {
      "displayName": "Roey Zaworbach",
      "userId": "02944633912131916379"
     },
     "user_tz": -180
    },
    "id": "GSq6f9MgNhG_",
    "outputId": "212eea25-3e3a-46f3-926a-d090faf6efa2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import random\n",
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "#!pip install --upgrade spacy\n",
    "import spacy\n",
    "from spacy.util import compounding, minibatch\n",
    "from spacy import displacy\n",
    "# Uncomment if you want Spacy to use GPU for training. Note - this will use transformer architecture\n",
    "spacy.require_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requirements for converting the dataframe to Spacy Docs\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "from spacy.language import Language\n",
    "from spacy.tokens import Doc, DocBin, Span\n",
    "from spacy.util import filter_spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models for evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import unicodedata as ud\n",
    "import warnings\n",
    "\n",
    "\n",
    "class LemmaEvaluator:\n",
    "    def __init__(self, nlp1, nlp2, nlp3=None, norm_method=None):\n",
    "        self.nlp1 = nlp1\n",
    "        self.nlp2 = nlp2\n",
    "        self.nlp3 = nlp3\n",
    "        self.norm_method = norm_method\n",
    "        \n",
    "        # check if normalization method is specified\n",
    "        if self.norm_method is None:\n",
    "            warnings.warn(\"Normalization method not specified. Text may not be normalized correctly.\", UserWarning)\n",
    "\n",
    "    def evaluate_lemmas(self, docs):\n",
    "        same_lemmas = 0\n",
    "        diff_lemmas = 0\n",
    "        correct_lemmas1 = 0\n",
    "        correct_lemmas2 = 0\n",
    "        correct_lemmas3 = 0\n",
    "        total_lemmas = 0\n",
    "\n",
    "        data = []\n",
    "\n",
    "        for doc in tqdm(docs, desc=\"Evaluating models\", total=len(docs)):\n",
    "            for token in doc:\n",
    "                try:\n",
    "                    gold_lemma = self.clean_text(token.lemma_)\n",
    "                    lemma1 = self.nlp1(self.clean_text(doc.text))[token.i].lemma_\n",
    "                    lemma2 = self.nlp2(self.clean_text(doc.text))[token.i].lemma_\n",
    "                    if self.nlp3 is not None:\n",
    "                        lemma3 = self.nlp3(self.clean_text(doc.text))[token.i].lemma_\n",
    "                    if self.nlp3 is not None and lemma1 == lemma2 == lemma3 ==gold_lemma:\n",
    "                        result = \"All lemmas are the same\"\n",
    "                        same_lemmas += 1\n",
    "                        correct_lemmas1 += 1\n",
    "                        correct_lemmas2 += 1\n",
    "                        correct_lemmas3 += 1\n",
    "                    elif lemma1 == lemma2 == gold_lemma:\n",
    "                        result = \"All lemmas are the same\"\n",
    "                        same_lemmas += 1\n",
    "                        correct_lemmas1 += 1\n",
    "                        correct_lemmas2 += 1\n",
    "                    else:\n",
    "                        result = \"\"\n",
    "                        diff_lemmas += 1\n",
    "                        if lemma1 == gold_lemma:\n",
    "                            correct_lemmas1 += 1\n",
    "                            result += f\", Model 1 correct ({lemma1})\"\n",
    "                        else:\n",
    "                            result += f\", Model 1 incorrect ({lemma1})\"\n",
    "                        if lemma2 == gold_lemma:\n",
    "                            correct_lemmas2 += 1\n",
    "                            result += f\", Model 2 correct ({lemma2})\"\n",
    "                        else:\n",
    "                            result += f\", Model 2 incorrect ({lemma2})\"\n",
    "                        if self.nlp3 is not None:\n",
    "                            if lemma3 == gold_lemma:\n",
    "                                correct_lemmas3 += 1\n",
    "                                result += f\", Model 3 correct ({lemma3})\"\n",
    "                            else:\n",
    "                                result += f\", Model 3 incorrect ({lemma3})\"\n",
    "                    if self.nlp3 is not None:\n",
    "                        data.append([doc.text, token.text, gold_lemma, lemma1, lemma2, lemma3, result])\n",
    "                    else:\n",
    "                        data.append([doc.text, token.text, gold_lemma, lemma1, lemma2, result])\n",
    "                    total_lemmas += 1\n",
    "                except IndexError as e:\n",
    "                    print(f\"Error occurred at token index {token.i} in document: {doc}\")\n",
    "                    print(f\"Error message: {e}\")\n",
    "\n",
    "        if self.nlp3 is not None:\n",
    "            df_evaluate = pd.DataFrame(data, columns=[\"Text\", \"Token\", \"Gold Lemma\", \"Model 1 Lemma\", \"Model 2 Lemma\", \"Model 3 Lemma\", \"Result\"])\n",
    "            print(df_evaluate)\n",
    "            print(f\"Total Lemmas: {total_lemmas}\")\n",
    "            print(f\"Total same lemmas: {same_lemmas}\")\n",
    "            print(f\"Total different lemmas: {diff_lemmas}\")\n",
    "            print(f\"Total correct lemmas for Model 1: {correct_lemmas1}\")\n",
    "            print(f\"Total correct lemmas for Model 2: {correct_lemmas2}\")\n",
    "            print(f\"Total correct lemmas for Model 3: {correct_lemmas3}\")\n",
    "        else:\n",
    "            df_evaluate = pd.DataFrame(data, columns=[\"Text\", \"Token\", \"Gold Lemma\", \"Model 1 Lemma\", \"Model 2 Lemma\", \"Result\"])\n",
    "            print(df_evaluate)\n",
    "            print(f\"Total Lemmas: {total_lemmas}\")\n",
    "            print(f\"Total same lemmas: {same_lemmas}\")\n",
    "            print(f\"Total different lemmas: {diff_lemmas}\")\n",
    "            print(f\"Total correct lemmas for Model 1: {correct_lemmas1}\")\n",
    "            print(f\"Total correct lemmas for Model 2: {correct_lemmas2}\")\n",
    "            \n",
    "        # calculate and print accuracy\n",
    "        if self.nlp3 is not None:\n",
    "            print(f\"Model 1 accuracy: {correct_lemmas1/total_lemmas:.2%}\")\n",
    "            print(f\"Model 2 accuracy: {correct_lemmas2/total_lemmas:.2%}\")\n",
    "            print(f\"Model 3 accuracy: {correct_lemmas3/total_lemmas:.2%}\")\n",
    "        else:\n",
    "            print(f\"Model 1 accuracy: {correct_lemmas1/total_lemmas:.2%}\")\n",
    "            print(f\"Model 2 accuracy: {correct_lemmas2/total_lemmas:.2%}\")\n",
    "            \n",
    "        return df_evaluate\n",
    "    \n",
    "    \n",
    "    def evaluate_line(self, line, model_name=\"Model\"):\n",
    "        doc = self.nlp1(line)\n",
    "        gold_lemmas = [token.lemma_ for token in doc]\n",
    "        lemma1 = [token.lemma_ for token in self.nlp1(line)]\n",
    "        lemma2 = [token.lemma_ for token in self.nlp2(line)]\n",
    "        if self.nlp3 is not None:\n",
    "            lemma3 = [token.lemma_ for token in self.nlp3(line)]\n",
    "        else:\n",
    "            lemma3 = None\n",
    "        # add NER labels to dataframe\n",
    "        NER1 = [token.ent_type_ for token in self.nlp1(line)]\n",
    "        NER2 = [token.ent_type_ for token in self.nlp2(line)]\n",
    "        if self.nlp3 is not None:\n",
    "            NER3 = [token.ent_type_ for token in self.nlp3(line)]\n",
    "        else:\n",
    "            NER3 = None    \n",
    "        data = {\"Gold Lemma\": gold_lemmas, f\"{model_name} 1 Lemma\": lemma1, f\"{model_name} 2 Lemma\": lemma2, f\"{model_name} 3 Lemma\": lemma3, f\"{model_name} 1 NER\": NER1, f\"{model_name} 2 NER\": NER2, f\"{model_name} 3 NER\": NER3}\n",
    "        if self.nlp3 is None:\n",
    "            del data[f\"{model_name} 3 Lemma\"]\n",
    "\n",
    "        df_evaluate_line = pd.DataFrame(data)\n",
    "        print(df_evaluate_line)\n",
    "        return df_evaluate_line\n",
    "        #print(data)\n",
    "        #return data\n",
    "    \n",
    "    def evaluate_ner(self, docs):\n",
    "        same_ner = 0\n",
    "        diff_ner = 0\n",
    "        correct_ner1 = 0\n",
    "        correct_ner2 = 0\n",
    "        correct_ner3 = 0\n",
    "\n",
    "        data = []\n",
    "\n",
    "        for doc in tqdm(docs, desc=\"Evaluating models\", total=len(docs)):\n",
    "            for ent in doc.ents:\n",
    "                gold_label = self.clean_text(ent.label_)\n",
    "                label1 = None\n",
    "                label2 = None\n",
    "                label3 = None\n",
    "                result=\"\"\n",
    "                for token in doc:\n",
    "                    if token.idx == ent.start_char:\n",
    "                        label1 = self.nlp1(self.clean_text(token.text))[0].ent_type_\n",
    "                        label2 = self.nlp2(self.clean_text(token.text))[0].ent_type_\n",
    "                        if self.nlp3 is not None:\n",
    "                            label3 = self.nlp3(self.clean_text(token.text))[0].ent_type_\n",
    "                            #print label3 character count\n",
    "                            if len(label3) > 0:\n",
    "                                print(token.text, \" | \", self.nlp3(self.clean_text(token.text))[0])\n",
    "                        break\n",
    "\n",
    "                if label3 is None and label1 == label2 == gold_label:\n",
    "                    result = \"All NER labels are the same\"\n",
    "                    same_ner += 1\n",
    "                    correct_ner1 += 1\n",
    "                    correct_ner2 += 1\n",
    "                elif label1 == label2 == label3 == gold_label:\n",
    "                    result = \"All NER labels are the same\"\n",
    "                    same_ner += 1\n",
    "                    correct_ner1 += 1\n",
    "                    correct_ner2 += 1\n",
    "                    correct_ner3 += 1\n",
    "                else:\n",
    "                    result = \"NER labels are different\"\n",
    "                diff_ner += 1\n",
    "                if label1 == gold_label:\n",
    "                    correct_ner1 += 1\n",
    "                    result += f\", Model 1 correct ({label1})\"\n",
    "                else:\n",
    "                    result += f\", Model 1 incorrect ({label1})\"\n",
    "                if label2 == gold_label:\n",
    "                    correct_ner2 += 1\n",
    "                    result += f\", Model 2 correct ({label2})\"\n",
    "                else:\n",
    "                    result += f\", Model 2 incorrect ({label2})\"\n",
    "                if self.nlp3 is not None and label3 == gold_label:\n",
    "                        correct_ner3 += 1\n",
    "                        result += f\", Model 3 correct ({label3})\"\n",
    "                else:\n",
    "                    result += f\", Model 3 incorrect ({label3})\"\n",
    "                if self.nlp3 is not None:\n",
    "                    data.append([doc.text, ent.text, gold_label, label1, label2, label3, result])\n",
    "                else:\n",
    "                    data.append([doc.text, ent.text, gold_label, label1, label2, result])\n",
    "        if self.nlp3 is not None:\n",
    "            df_evaluate_ner = pd.DataFrame(data, columns=[\"Text\", \"Entity\", \"Gold Label\", \"Model 1 Label\", \"Model 2 Label\", \"Model 3 Label\", \"Result\"])\n",
    "        else:\n",
    "            df_evaluate_ner = pd.DataFrame(data, columns=[\"Text\", \"Entity\", \"Gold Label\", \"Model 1 Label\", \"Model 2 Label\", \"Result\"])\n",
    "        print(df_evaluate_ner)\n",
    "\n",
    "        total = same_ner + diff_ner\n",
    "        print(f\"Total same NER labels: {same_ner} ({same_ner/total:.2%})\")\n",
    "        print(f\"Total different NER labels: {diff_ner} ({diff_ner/total:.2%})\")\n",
    "        print(f\"Model 1 accuracy: {correct_ner1/total:.2%}\")\n",
    "        print(f\"Model 2 accuracy: {correct_ner2/total:.2%}\")\n",
    "        if self.nlp3 is not None:\n",
    "            print(f\"Model 3 accuracy: {correct_ner3/total:.2%}\")\n",
    "\n",
    "        return df_evaluate_ner\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        # Check if the normalization method is valid\n",
    "        if self.norm_method is not None and self.norm_method not in ['NFD', 'NFC', 'NFKD', 'NFKC']:\n",
    "            raise ValueError(\"Normalization method is not valid. Must be one of ['NFD', 'NFC', 'NFKD', 'NFKC'].\")\n",
    "        elif self.norm_method is not None:\n",
    "            cleaned = re.sub(r\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "            cleaned = ud.normalize(self.norm_method, cleaned)\n",
    "        else:\n",
    "            cleaned = text\n",
    "        return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/atlomy_nlp/lib/python3.11/site-packages/spacy/util.py:887: UserWarning: [W095] Model 'grc_pipeline' (0.0.0) was trained with spaCy v3.4 and may not be 100% compatible with the current version (3.5.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/tmp/ipykernel_1312/269188743.py:16: UserWarning: Normalization method not specified. Text may not be normalized correctly.\n",
      "  warnings.warn(\"Normalization method not specified. Text may not be normalized correctly.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gold Lemma Model 1 Lemma Model 2 Lemma     Model 3 Lemma Model 1 NER  \\\n",
      "0                                                                         \n",
      "1    Ἔχομαι      Ἔχομαι         Ἔχω             Ἔχω               \n",
      "2         δὲ           δὲ           δὲ               δὲ               \n",
      "3   διαφορὰς     διαφορὰς     διαφορὰς         διαφορὰς               \n",
      "4     πολλάς       πολλάς       πολλάς           πολλάς               \n",
      "5           ,             ,             ,                 ,               \n",
      "6    καθάπερ      καθάπερ      καθάπερ          καθάπερ               \n",
      "7          ἡ            ἡ            ἡ                ὁ               \n",
      "8     κοιλία       κοιλία       κοιλία           κοιλία               \n",
      "9           ,             ,             ,                 ,               \n",
      "10       καὶ          καὶ          καὶ               καί               \n",
      "11     τοῦτο        τοῦτο        τοῦτο            τοῦτο               \n",
      "12        τὸ           τὸ           τὸ  ὁ μέν...ὁ δέ               \n",
      "13    μόριος       μόριος       μόριον           μόριον               \n",
      "\n",
      "   Model 2 NER Model 3 NER  \n",
      "0                           \n",
      "1                           \n",
      "2                           \n",
      "3                  Medical  \n",
      "4                           \n",
      "5                           \n",
      "6                           \n",
      "7                           \n",
      "8                Body Part  \n",
      "9                           \n",
      "10                          \n",
      "11                          \n",
      "12                          \n",
      "13                          \n"
     ]
    }
   ],
   "source": [
    "line=\"Ἐξήρτηται δ' ἐκ τῆς μεγάλης φλεβὸς καὶ τῆς ἀορτῆς, καὶ δι' αὐτοῦ φλέβες πολλαὶ καὶ πυκναί, κατατείνουσαι πρὸς τὴν τῶν ἐντέρων θέσιν, ἄνωθεν ἀρξάμεναι μέχρι κάτω\"\n",
    "#line = \"Τείνει δὲ πρῶτον μὲν ἄνω ἀπὸ τῆς καρδίας τῆς μεγάλης φλεβὸς μόριον πρὸς τὸν πλεύμονα καὶ τὴν σύναψιν τῆς ἀορτῆς, ἄσχιστος καὶ μεγάλη οὖσα φλέψ\"\n",
    "#line = \"'ᾗ δὲ συνήρτηται κοῖλόν ἐστιν.\"\n",
    "line = \" Ἔχει δὲ διαφορὰς πολλάς, καθάπερ ἡ κοιλία, καὶ τοῦτο τὸ μόριον\"\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Doc, DocBin, Span\n",
    "spacy.prefer_gpu()\n",
    "\n",
    "#Lemma Evaluations:\n",
    "nlp1 = spacy.load(\"grc_proiel_trf\")\n",
    "nlp2 = spacy.load(\"grc_odycy_joint_trf\")\n",
    "nlp3 = spacy.load('../training/grc_ud_proiel_trf_Lem_NER/model-best') #this is an old model from march 23\n",
    "\n",
    "evaluator = LemmaEvaluator(nlp1, nlp2, nlp3)\n",
    "\n",
    "evaluate_quote = evaluator.evaluate_line(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line=\"Ἐξήρτηται δ' ἐκ τῆς μεγάλης φλεβὸς καὶ τῆς ἀορτῆς, καὶ δι' αὐτοῦ φλέβες πολλαὶ καὶ πυκναί, κατατείνουσαι πρὸς τὴν τῶν ἐντέρων θέσιν, ἄνωθεν ἀρξάμεναι μέχρι κάτω\"\n",
    "#line = \" Ἔχει δὲ διαφορὰς πολλάς, καθάπερ ἡ κοιλία, καὶ τοῦτο τὸ μόριον\"\n",
    "\n",
    "nlp1 = spacy.load('../training/ATLOMY_G_NER_pipeline/sm/model-best')\n",
    "linenlp = nlp1(line)\n",
    "for token in linenlp:\n",
    "    print(token.text, token.ent_iob_, token.ent_type_, \"| \", token.lemma_)\n",
    "#for ent in linenlp.ents:\n",
    "#    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \" Ἐξήρτηται δ' ἐκ τῆς μεγάλης φλεβὸς καὶ τῆς ἀορτῆς, καὶ δι' αὐτοῦ φλέβες πολλαὶ καὶ πυκναί, κατατείνουσαι πρὸς τὴν τῶν ἐντέρων θέσιν, ἄνωθεν ἀρξάμεναι μέχρι κάτω\"\n",
    "line = \"Ἐξήρτηται δ' ἐκ τῆς μεγάλης φλεβὸςκαὶ τῆς ἀορτῆς, καὶ δι' αὐτοῦ φλέβες πολλαὶ καὶ πυκναί, κατατείνουσαι πρὸς τὴν τῶν ἐντέρων θέσιν, ἄνωθεν ἀρξάμεναι μέχρι κάτω\"\n",
    "# get gold entities for docs[1]\n",
    "# if doc.text == line:\n",
    "for doc in docs:\n",
    "    if doc.text == line:\n",
    "        print(doc.text)\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/atlomy_nlp/lib/python3.11/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'grc_pipeline' (0.0.0) was trained with spaCy v3.7.2 and may not be 100% compatible with the current version (3.6.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/root/anaconda3/envs/atlomy_nlp/lib/python3.11/site-packages/spacy_transformers/layers/hf_shim.py:137: UserWarning: Error loading saved torch state_dict with strict=True, likely due to differences between 'transformers' versions. Attempting to load with strict=False as a fallback...\n",
      "\n",
      "If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current 'transformers' and 'spacy-transformers' versions. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/root/anaconda3/envs/atlomy_nlp/lib/python3.11/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'grc_pipeline' (0.0.0) was trained with spaCy v3.5.3 and may not be 100% compatible with the current version (3.6.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "Evaluating models:   3%|▎         | 3/92 [00:06<03:13,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at token index 56 in document: ἐντεῦθεν δὲ αἱ μὲν ἐς τράχηλον αἱ δὲ ἐπʼ ὠμοπλάτας αἱ δὲ ἀποκαμφθεῖσαι κάτω παρὰ σπονδύλους καὶ πλευρὰς ἀποκλίνουσιν ἐξ ἀριστερῶν μὲν μία | ἐγγὺς κληΐδων, ἐκ δεξιῶν δὲ [ἐπί τι αὐτὴ χωρίον] ἄλλη [ἡ δὲ] σμικρὸν κατωτέρω ἀποκαμφθεῖσα ὅθεν μὲν ἐκείνη ἀπέλιπε προσέδωκε τῇσι πλευρῇσιν ἔστʼ ἂν τῇ ἐπʼ αὐτῆς τῆς καρδίης προστύχῃ ἀποκαμπτομένῃ ἐς τὰ ἀριστερά·\n",
      "Error message: [E040] Attempt to access token at 56, max length 56.\n",
      "Error occurred at token index 57 in document: ἐντεῦθεν δὲ αἱ μὲν ἐς τράχηλον αἱ δὲ ἐπʼ ὠμοπλάτας αἱ δὲ ἀποκαμφθεῖσαι κάτω παρὰ σπονδύλους καὶ πλευρὰς ἀποκλίνουσιν ἐξ ἀριστερῶν μὲν μία | ἐγγὺς κληΐδων, ἐκ δεξιῶν δὲ [ἐπί τι αὐτὴ χωρίον] ἄλλη [ἡ δὲ] σμικρὸν κατωτέρω ἀποκαμφθεῖσα ὅθεν μὲν ἐκείνη ἀπέλιπε προσέδωκε τῇσι πλευρῇσιν ἔστʼ ἂν τῇ ἐπʼ αὐτῆς τῆς καρδίης προστύχῃ ἀποκαμπτομένῃ ἐς τὰ ἀριστερά·\n",
      "Error message: [E040] Attempt to access token at 57, max length 56.\n",
      "Error occurred at token index 58 in document: ἐντεῦθεν δὲ αἱ μὲν ἐς τράχηλον αἱ δὲ ἐπʼ ὠμοπλάτας αἱ δὲ ἀποκαμφθεῖσαι κάτω παρὰ σπονδύλους καὶ πλευρὰς ἀποκλίνουσιν ἐξ ἀριστερῶν μὲν μία | ἐγγὺς κληΐδων, ἐκ δεξιῶν δὲ [ἐπί τι αὐτὴ χωρίον] ἄλλη [ἡ δὲ] σμικρὸν κατωτέρω ἀποκαμφθεῖσα ὅθεν μὲν ἐκείνη ἀπέλιπε προσέδωκε τῇσι πλευρῇσιν ἔστʼ ἂν τῇ ἐπʼ αὐτῆς τῆς καρδίης προστύχῃ ἀποκαμπτομένῃ ἐς τὰ ἀριστερά·\n",
      "Error message: [E040] Attempt to access token at 58, max length 56.\n",
      "Error occurred at token index 59 in document: ἐντεῦθεν δὲ αἱ μὲν ἐς τράχηλον αἱ δὲ ἐπʼ ὠμοπλάτας αἱ δὲ ἀποκαμφθεῖσαι κάτω παρὰ σπονδύλους καὶ πλευρὰς ἀποκλίνουσιν ἐξ ἀριστερῶν μὲν μία | ἐγγὺς κληΐδων, ἐκ δεξιῶν δὲ [ἐπί τι αὐτὴ χωρίον] ἄλλη [ἡ δὲ] σμικρὸν κατωτέρω ἀποκαμφθεῖσα ὅθεν μὲν ἐκείνη ἀπέλιπε προσέδωκε τῇσι πλευρῇσιν ἔστʼ ἂν τῇ ἐπʼ αὐτῆς τῆς καρδίης προστύχῃ ἀποκαμπτομένῃ ἐς τὰ ἀριστερά·\n",
      "Error message: [E040] Attempt to access token at 59, max length 56.\n",
      "Error occurred at token index 60 in document: ἐντεῦθεν δὲ αἱ μὲν ἐς τράχηλον αἱ δὲ ἐπʼ ὠμοπλάτας αἱ δὲ ἀποκαμφθεῖσαι κάτω παρὰ σπονδύλους καὶ πλευρὰς ἀποκλίνουσιν ἐξ ἀριστερῶν μὲν μία | ἐγγὺς κληΐδων, ἐκ δεξιῶν δὲ [ἐπί τι αὐτὴ χωρίον] ἄλλη [ἡ δὲ] σμικρὸν κατωτέρω ἀποκαμφθεῖσα ὅθεν μὲν ἐκείνη ἀπέλιπε προσέδωκε τῇσι πλευρῇσιν ἔστʼ ἂν τῇ ἐπʼ αὐτῆς τῆς καρδίης προστύχῃ ἀποκαμπτομένῃ ἐς τὰ ἀριστερά·\n",
      "Error message: [E040] Attempt to access token at 60, max length 56.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:   4%|▍         | 4/92 [00:14<06:18,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at token index 61 in document: ἐντεῦθεν δὲ αἱ μὲν ἐς τράχηλον αἱ δὲ ἐπʼ ὠμοπλάτας αἱ δὲ ἀποκαμφθεῖσαι κάτω παρὰ σπονδύλους καὶ πλευρὰς ἀποκλίνουσιν ἐξ ἀριστερῶν μὲν μία | ἐγγὺς κληΐδων, ἐκ δεξιῶν δὲ [ἐπί τι αὐτὴ χωρίον] ἄλλη [ἡ δὲ] σμικρὸν κατωτέρω ἀποκαμφθεῖσα ὅθεν μὲν ἐκείνη ἀπέλιπε προσέδωκε τῇσι πλευρῇσιν ἔστʼ ἂν τῇ ἐπʼ αὐτῆς τῆς καρδίης προστύχῃ ἀποκαμπτομένῃ ἐς τὰ ἀριστερά·\n",
      "Error message: [E026] Error accessing token at position 61: out of bounds in Doc of length 56.\n",
      "Error occurred at token index 62 in document: ἐντεῦθεν δὲ αἱ μὲν ἐς τράχηλον αἱ δὲ ἐπʼ ὠμοπλάτας αἱ δὲ ἀποκαμφθεῖσαι κάτω παρὰ σπονδύλους καὶ πλευρὰς ἀποκλίνουσιν ἐξ ἀριστερῶν μὲν μία | ἐγγὺς κληΐδων, ἐκ δεξιῶν δὲ [ἐπί τι αὐτὴ χωρίον] ἄλλη [ἡ δὲ] σμικρὸν κατωτέρω ἀποκαμφθεῖσα ὅθεν μὲν ἐκείνη ἀπέλιπε προσέδωκε τῇσι πλευρῇσιν ἔστʼ ἂν τῇ ἐπʼ αὐτῆς τῆς καρδίης προστύχῃ ἀποκαμπτομένῃ ἐς τὰ ἀριστερά·\n",
      "Error message: [E026] Error accessing token at position 62: out of bounds in Doc of length 56.\n",
      "Error occurred at token index 63 in document: ἐντεῦθεν δὲ αἱ μὲν ἐς τράχηλον αἱ δὲ ἐπʼ ὠμοπλάτας αἱ δὲ ἀποκαμφθεῖσαι κάτω παρὰ σπονδύλους καὶ πλευρὰς ἀποκλίνουσιν ἐξ ἀριστερῶν μὲν μία | ἐγγὺς κληΐδων, ἐκ δεξιῶν δὲ [ἐπί τι αὐτὴ χωρίον] ἄλλη [ἡ δὲ] σμικρὸν κατωτέρω ἀποκαμφθεῖσα ὅθεν μὲν ἐκείνη ἀπέλιπε προσέδωκε τῇσι πλευρῇσιν ἔστʼ ἂν τῇ ἐπʼ αὐτῆς τῆς καρδίης προστύχῃ ἀποκαμπτομένῃ ἐς τὰ ἀριστερά·\n",
      "Error message: [E026] Error accessing token at position 63: out of bounds in Doc of length 56.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  12%|█▏        | 11/92 [00:30<03:04,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at token index 19 in document: Καλεῖται δὲ τούτων τὰ μὲν ὑστέρα καὶ δελφύς (ὅθεν καὶ ἀδελφοὺς προσαγορεύουσι), μήτρα δʼ ὁ καυλὸς καὶ τὸ στόμα τῆς ὑστέρας.\n",
      "Error message: [E040] Attempt to access token at 19, max length 19.\n",
      "Error occurred at token index 20 in document: Καλεῖται δὲ τούτων τὰ μὲν ὑστέρα καὶ δελφύς (ὅθεν καὶ ἀδελφοὺς προσαγορεύουσι), μήτρα δʼ ὁ καυλὸς καὶ τὸ στόμα τῆς ὑστέρας.\n",
      "Error message: [E040] Attempt to access token at 20, max length 19.\n",
      "Error occurred at token index 21 in document: Καλεῖται δὲ τούτων τὰ μὲν ὑστέρα καὶ δελφύς (ὅθεν καὶ ἀδελφοὺς προσαγορεύουσι), μήτρα δʼ ὁ καυλὸς καὶ τὸ στόμα τῆς ὑστέρας.\n",
      "Error message: [E040] Attempt to access token at 21, max length 19.\n",
      "Error occurred at token index 22 in document: Καλεῖται δὲ τούτων τὰ μὲν ὑστέρα καὶ δελφύς (ὅθεν καὶ ἀδελφοὺς προσαγορεύουσι), μήτρα δʼ ὁ καυλὸς καὶ τὸ στόμα τῆς ὑστέρας.\n",
      "Error message: [E040] Attempt to access token at 22, max length 19.\n",
      "Error occurred at token index 23 in document: Καλεῖται δὲ τούτων τὰ μὲν ὑστέρα καὶ δελφύς (ὅθεν καὶ ἀδελφοὺς προσαγορεύουσι), μήτρα δʼ ὁ καυλὸς καὶ τὸ στόμα τῆς ὑστέρας.\n",
      "Error message: [E040] Attempt to access token at 23, max length 19.\n",
      "Error occurred at token index 24 in document: Καλεῖται δὲ τούτων τὰ μὲν ὑστέρα καὶ δελφύς (ὅθεν καὶ ἀδελφοὺς προσαγορεύουσι), μήτρα δʼ ὁ καυλὸς καὶ τὸ στόμα τῆς ὑστέρας.\n",
      "Error message: [E026] Error accessing token at position 24: out of bounds in Doc of length 19.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models: 100%|██████████| 92/92 [03:23<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text     Token Gold Lemma  \\\n",
      "0     Τὰ μὲν οὖν ἄνωθεν τῆς καρδίας τοῦτον ...       Τὰ         ὁ   \n",
      "1     Τὰ μὲν οὖν ἄνωθεν τῆς καρδίας τοῦτον ...      μὲν       μέν   \n",
      "2     Τὰ μὲν οὖν ἄνωθεν τῆς καρδίας τοῦτον ...     οὖν      οὖν   \n",
      "3     Τὰ μὲν οὖν ἄνωθεν τῆς καρδίας τοῦτον ...  ἄνωθεν   ἄνωθεν   \n",
      "4     Τὰ μὲν οὖν ἄνωθεν τῆς καρδίας τοῦτον ...      τῆς         ὁ   \n",
      "...                                                 ...       ...        ...   \n",
      "1821  Ἐν πᾶσι δʼ ἔχει ὁμοίως τοῖς ἄλλοις κα...     τοῖς         ὁ   \n",
      "1822  Ἐν πᾶσι δʼ ἔχει ὁμοίως τοῖς ἄλλοις κα...  ἄλλοις    ἄλλος   \n",
      "1823  Ἐν πᾶσι δʼ ἔχει ὁμοίως τοῖς ἄλλοις κα...      καὶ       καί   \n",
      "1824  Ἐν πᾶσι δʼ ἔχει ὁμοίως τοῖς ἄλλοις κα...    τοῦτο    οὗτος   \n",
      "1825  Ἐν πᾶσι δʼ ἔχει ὁμοίως τοῖς ἄλλοις κα...         .          .   \n",
      "\n",
      "     Model 1 Lemma Model 2 Lemma Model 3 Lemma                   Result  \n",
      "0               ὁ            ὁ            ὁ  All lemmas are the same  \n",
      "1             μέν          μέν          μέν  All lemmas are the same  \n",
      "2            οὖν         οὖν         οὖν  All lemmas are the same  \n",
      "3         ἄνωθεν      ἄνωθεν      ἄνωθεν  All lemmas are the same  \n",
      "4               ὁ            ὁ            ὁ  All lemmas are the same  \n",
      "...            ...           ...           ...                      ...  \n",
      "1821            ὁ            ὁ            ὁ  All lemmas are the same  \n",
      "1822       ἄλλος       ἄλλος       ἄλλος  All lemmas are the same  \n",
      "1823          καί          καί          καί  All lemmas are the same  \n",
      "1824       οὗτος       οὗτος       οὗτος  All lemmas are the same  \n",
      "1825             .             .             .  All lemmas are the same  \n",
      "\n",
      "[1826 rows x 7 columns]\n",
      "Total Lemmas: 1826\n",
      "Total same lemmas: 1479\n",
      "Total different lemmas: 347\n",
      "Total correct lemmas for Model 1: 1524\n",
      "Total correct lemmas for Model 2: 1644\n",
      "Total correct lemmas for Model 3: 1719\n",
      "Model 1 accuracy: 83.46%\n",
      "Model 2 accuracy: 90.03%\n",
      "Model 3 accuracy: 94.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc, DocBin, Span\n",
    "spacy.prefer_gpu()\n",
    "\n",
    "#Lemma Evaluations:\n",
    "#nlp1 = spacy.load(\"../training/ATLOMY_G_NER_pipeline/sm/model-best\")\n",
    "#nlp2 = spacy.load(\"../training/ATLOMY_G_NER_pipeline/sm_3_sep/model-best\") # this is a model from Sep 3\n",
    "#nlp3 = spacy.load('../training/grc_ud_proiel_trf_Lem_NER/model-best') #this is an old model from march 23\n",
    "#nlp1 = spacy.load('../training/ATLOMY_G_NER_pipeline/sm_10_dec/model-best') # this is a model from Sep 15\n",
    "\n",
    "nlp1 = spacy.load('../training/SageMaker/NER/ner_22_dec_trf/model-best')\n",
    "nlp2 = spacy.load('../training/SageMaker/NER/ner_22_dec_vec/model-best')\n",
    "nlp3 = spacy.load('../training/ATLOMY_G_NER_pipeline/sm_3_sep/model-best')\n",
    "\n",
    "evaluator = LemmaEvaluator(nlp1, nlp2, nlp3, norm_method='NFKD')\n",
    "\n",
    "test_docs = DocBin().from_disk('../corpus/test/lemma_test/test_lemma_NFKD.spacy')\n",
    "docs = list(test_docs.get_docs(nlp1.vocab))#[:10]\n",
    "\n",
    "df_evaluate_lemmas = evaluator.evaluate_lemmas(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp1 = spacy.load('../training/ATLOMY_G_NER_pipeline/sm_15_sep/model-best') # this is a model from Sep 15\n",
    "test_docs = DocBin().from_disk('../corpus/dev/ner_dev/ner_dev_NFKC.spacy')\n",
    "docs = list(test_docs.get_docs(nlp1.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs\n",
    "#ἀποκαμφθεῖσα δὲ κάτω ἐπὶ σπονδύλους καταβαίνει ἔστ ̓ ἂν ἀφίκηται"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/atlomy_nlp/lib/python3.11/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'grc_pipeline' (0.0.0) was trained with spaCy v3.7.2 and may not be 100% compatible with the current version (3.6.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/root/anaconda3/envs/atlomy_nlp/lib/python3.11/site-packages/spacy_transformers/layers/hf_shim.py:137: UserWarning: Error loading saved torch state_dict with strict=True, likely due to differences between 'transformers' versions. Attempting to load with strict=False as a fallback...\n",
      "\n",
      "If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current 'transformers' and 'spacy-transformers' versions. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/root/anaconda3/envs/atlomy_nlp/lib/python3.11/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'grc_pipeline' (0.0.0) was trained with spaCy v3.5.3 and may not be 100% compatible with the current version (3.6.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "Evaluating models:   0%|          | 0/44 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "κάτω  |  κάτω\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:   2%|▏         | 1/44 [00:00<00:13,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ὑείᾳ  |  ὑείᾳ\n",
      "Αἱ  |  Αἱ\n",
      "ἀρχαὶ  |  ἀρχαὶ\n",
      "φλεβῶν  |  φλεβῶν\n",
      ",  |  ,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:   5%|▍         | 2/44 [00:01<00:40,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",  |  ,\n",
      "σφαγίτιδες  |  σφαγίτιδες\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:   7%|▋         | 3/44 [00:02<00:26,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "κεφαλὴ  |  κεφαλὴ\n",
      "ἐγκέφαλος  |  ἐγκέφαλος\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:   9%|▉         | 4/44 [00:02<00:19,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "διμερὴς  |  διμερὴς\n",
      "πλεύμων  |  πλεύμων\n",
      "φλὲψ  |  φλὲψ\n",
      "διὰ  |  διὰ\n",
      "καρδίας  |  καρδίας\n",
      ",  |  ,\n",
      "ἀορτὴν  |  ἀορτὴν\n",
      "ἀπὸ  |  ἀπὸ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  11%|█▏        | 5/44 [00:03<00:26,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "καρδίας  |  καρδίας\n",
      "τὸ  |  τὸ\n",
      "διφυὲς  |  διφυὲς\n",
      "στόματος  |  στόματος\n",
      "παρίσθμιον  |  παρίσθμιον\n",
      ",  |  ,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  14%|█▎        | 6/44 [00:04<00:29,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "δὲ  |  δὲ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  16%|█▌        | 7/44 [00:04<00:22,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "καρδία  |  καρδία\n",
      "κοιλίαις  |  κοιλίαις\n",
      "φλέβες  |  φλέβες\n",
      "πόθεν  |  πόθεν\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  18%|█▊        | 8/44 [00:05<00:22,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ἤρτηνται  |  ἤρτηνται\n",
      "ἀρχάς  |  ἀρχάς\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  20%|██        | 9/44 [00:05<00:19,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "μεγάλῃ  |  μεγάλῃ\n",
      "ἀορτῇ  |  ἀορτῇ\n",
      "Τείνουσι  |  Τείνουσι\n",
      "ἀπὸ  |  ἀπὸ\n",
      "ἀορτῆς  |  ἀορτῆς\n",
      "φλεβὸς  |  φλεβὸς\n",
      "ἀπὸ  |  ἀπὸ\n",
      "σχιζομένων  |  σχιζομένων\n",
      ",  |  ,\n",
      "ἐπὶ  |  ἐπὶ\n",
      "βουβῶνας  |  βουβῶνας\n",
      "μεγάλαι  |  μεγάλαι\n",
      "κοῖλαι  |  κοῖλαι\n",
      "διὰ  |  διὰ\n",
      "σκελῶν  |  σκελῶν\n",
      "τελευτῶσιν  |  τελευτῶσιν\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  23%|██▎       | 10/44 [00:07<00:34,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "εἰς  |  εἰς\n",
      "ἐπίπλοον  |  ἐπίπλοον\n",
      "ἀπὸ  |  ἀπὸ\n",
      "μέσης  |  μέσης\n",
      "κοιλίας  |  κοιλίας\n",
      "φύσιν  |  φύσιν\n",
      "ὑμὴν  |  ὑμὴν\n",
      "πιμελώδης  |  πιμελώδης\n",
      "μονοκοιλίοις  |  μονοκοιλίοις\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  25%|██▌       | 11/44 [00:08<00:35,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ἀμφώδουσιν  |  ἀμφώδουσιν\n",
      "διάστασις  |  διάστασις\n",
      "φανερά  |  φανερά\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  30%|██▉       | 13/44 [00:09<00:20,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",  |  ,\n",
      "πνεύμονα  |  πνεύμονα\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  32%|███▏      | 14/44 [00:09<00:16,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "κεφαλὴν  |  κεφαλὴν\n",
      "ἐγκέφαλον  |  ἐγκέφαλον\n",
      "εἰς  |  εἰς\n",
      "εἰς  |  εἰς\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  34%|███▍      | 15/44 [00:10<00:15,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "νεφρῶν  |  νεφρῶν\n",
      "πόδας  |  πόδας\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  36%|███▋      | 16/44 [00:10<00:12,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "δακτύλους  |  δακτύλους\n",
      "μέσον  |  μέσον\n",
      "διείργει  |  διείργει\n",
      "μῆνιγξ  |  μῆνιγξ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  39%|███▊      | 17/44 [00:10<00:12,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "λεπτή  |  λεπτή\n",
      "πόροι  |  πόροι\n",
      "συγκεχυμένοι  |  συγκεχυμένοι\n",
      "ὀλίγας  |  ὀλίγας\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  41%|████      | 18/44 [00:11<00:12,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ἶνας  |  ἶνας\n",
      "φλεβῶν  |  φλεβῶν\n",
      "ὑπεράνω  |  ὑπεράνω\n",
      "ἀπὸ  |  ἀπὸ\n",
      "ἐκ  |  ἐκ\n",
      "καρδίας  |  καρδίας\n",
      "ὅλη  |  ὅλη\n",
      "σχίζεται  |  σχίζεται\n",
      "εἰς  |  εἰς\n",
      "δύο  |  δύο\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  43%|████▎     | 19/44 [00:12<00:17,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "τόπους  |  τόπους\n",
      "δικραίῳ  |  δικραίῳ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  45%|████▌     | 20/44 [00:12<00:13,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "κνήμη  |  κνήμη\n",
      "ἄνωθεν  |  ἄνωθεν\n",
      "μύλη  |  μύλη\n",
      "ἄρθρον  |  ἄρθρον\n",
      "σαρκός  |  σαρκός\n",
      "κνήμην  |  κνήμην\n",
      "κάτωθεν  |  κάτωθεν\n",
      "ποδὸς  |  ποδὸς\n",
      "σφυρὰ  |  σφυρὰ\n",
      "τελευτώσιν  |  τελευτώσιν\n",
      "ἄνωθεν  |  ἄνωθεν\n",
      "γούνατος  |  γούνατος\n",
      "εξήκουσι  |  εξήκουσι\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  50%|█████     | 22/44 [00:15<00:16,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ἄρθρον  |  ἄρθρον\n",
      "φλεβῶν  |  φλεβῶν\n",
      "εἰς  |  εἰς\n",
      "πόροι  |  πόροι\n",
      "ἔκ  |  ἔκ\n",
      "φλεβὸς  |  φλεβὸς\n",
      "ἀορτῆς  |  ἀορτῆς\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  52%|█████▏    | 23/44 [00:16<00:17,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "εἰς  |  εἰς\n",
      "κοῖλον  |  κοῖλον\n",
      "πόροι  |  πόροι\n",
      "τείνοντες  |  τείνοντες\n",
      "εἰς  |  εἰς\n",
      "εἰς  |  εἰς\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  55%|█████▍    | 24/44 [00:16<00:16,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "νεφρῶν  |  νεφρῶν\n",
      "ἀποτομαὶ  |  ἀποτομαὶ\n",
      "φλεβίων  |  φλεβίων\n",
      "εἰς  |  εἰς\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  57%|█████▋    | 25/44 [00:17<00:14,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "κύστιν  |  κύστιν\n",
      "καθήκουσιν  |  καθήκουσιν\n",
      "ἄνω  |  ἄνω\n",
      "κεφαλῇ  |  κεφαλῇ\n",
      "κάτω  |  κάτω\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  59%|█████▉    | 26/44 [00:18<00:13,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ἕδρῃ.  |  ἕδρῃ\n",
      "περόναι  |  περόναι\n",
      "ἁπαλαὶ  |  ἁπαλαὶ\n",
      "ἐξήκουσιν  |  ἐξήκουσιν\n",
      "ἄνω  |  ἄνω\n",
      "κάτω  |  κάτω\n",
      "ὀστέῳ  |  ὀστέῳ\n",
      "χεῖρα  |  χεῖρα\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  61%|██████▏   | 27/44 [00:19<00:14,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "χείρες  |  χείρες\n",
      "άρθρα  |  άρθρα\n",
      "σύριγγα  |  σύριγγα\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  64%|██████▎   | 28/44 [00:19<00:11,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ἀπάντικρυ  |  ἀπάντικρυ\n",
      "μία  |  μία\n",
      "στόμα  |  στόμα\n",
      "ἕν  |  ἕν\n",
      "σαρκώδης  |  σαρκώδης\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  66%|██████▌   | 29/44 [00:20<00:12,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "χονδρώδης  |  χονδρώδης\n",
      "κεφαλὴν  |  κεφαλὴν\n",
      "νεύρα  |  νεύρα\n",
      "ἴνες  |  ἴνες\n",
      "νεύροισι  |  νεύροισι\n",
      "ὀστέου  |  ὀστέου\n",
      "σαρκός  |  σαρκός\n",
      "λεπτότεροι  |  λεπτότεροι\n",
      "στερεώτεροι  |  στερεώτεροι\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  68%|██████▊   | 30/44 [00:22<00:13,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "νευροκοίλιοι  |  νευροκοίλιοι\n",
      "ὅμοιαι  |  ὅμοιαι\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  70%|███████   | 31/44 [00:22<00:09,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ὑπένερθε  |  ὑπένερθε\n",
      "ἰθυωρίην  |  ἰθυωρίην\n",
      "μαζῷ  |  μαζῷ\n",
      "ἀριστερῷ  |  ἀριστερῷ\n",
      "ὅπῃ  |  ὅπῃ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  73%|███████▎  | 32/44 [00:23<00:10,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ἅλμα  |  ἅλμα\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  77%|███████▋  | 34/44 [00:23<00:05,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "φλεβὼν  |  φλεβὼν\n",
      "νεύρων  |  νεύρων\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  80%|███████▉  | 35/44 [00:24<00:04,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "καρδίης  |  καρδίης\n",
      "πνεύμων  |  πνεύμων\n",
      "συνεξαναπληροῖ  |  συνεξαναπληροῖ\n",
      "ἀριστερὰ  |  ἀριστερὰ\n",
      "πέντε  |  πέντε\n",
      "ὑπερκορυφώσιας  |  ὑπερκορυφώσιας\n",
      "λοβοὺς  |  λοβοὺς\n",
      "τεφρίνης  |  τεφρίνης\n",
      "χροιῆς  |  χροιῆς\n",
      "στίγμασιν  |  στίγμασιν\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  84%|████████▍ | 37/44 [00:25<00:04,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "τενθρηνιώδης  |  τενθρηνιώδης\n",
      "πλευρῆς  |  πλευρῆς\n",
      "ἀριστερῆς  |  ἀριστερῆς\n",
      "σπλὴν  |  σπλὴν\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  86%|████████▋ | 38/44 [00:26<00:04,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ποδός  |  ποδός\n",
      "Κοιλίη  |  Κοιλίη\n",
      "ἥπατι  |  ἥπατι\n",
      "παρακειμένη  |  παρακειμένη\n",
      "εὐώνυμον  |  εὐώνυμον\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  89%|████████▊ | 39/44 [00:27<00:03,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "νευρώδης  |  νευρώδης\n",
      "κύστιν  |  κύστιν\n",
      "ζῳοτόκα  |  ζῳοτόκα\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  91%|█████████ | 40/44 [00:28<00:02,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "τόνοι  |  τόνοι\n",
      "ἐγκεφάλου  |  ἐγκεφάλου\n",
      "ὑπὸ  |  ὑπὸ\n",
      "ὀστέον  |  ὀστέον\n",
      "μεγάλου  |  μεγάλου\n",
      "σπονδύλου  |  σπονδύλου\n",
      "ἄνωθεν  |  ἄνωθεν\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  93%|█████████▎| 41/44 [00:29<00:02,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "στομάχου  |  στομάχου\n",
      "φρένες  |  φρένες\n",
      "κατὰ  |  κατὰ\n",
      "κάτωθεν  |  κάτωθεν\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  95%|█████████▌| 42/44 [00:29<00:01,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ἀρτηρίης  |  ἀρτηρίης\n",
      "φλέβες  |  φλέβες\n",
      "ἐν  |  ἐν\n",
      "ὤτων  |  ὤτων\n",
      "φλεβών  |  φλεβών\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  98%|█████████▊| 43/44 [00:30<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ὦτα  |  ὦτα\n",
      "ὦτα  |  ὦτα\n",
      "Ἡπατῖτις  |  Ἡπατῖτις\n",
      "ὀσφύϊ  |  ὀσφύϊ\n",
      "μεγάλου  |  μεγάλου\n",
      "σπονδύλου  |  σπονδύλου\n",
      "κάτωθεν  |  κάτωθεν\n",
      "σπονδύλοισι  |  σπονδύλοισι\n",
      "ἐντεῦθεν  |  ἐντεῦθεν\n",
      "ἥπατος  |  ἥπατος\n",
      "διὰ  |  διὰ\n",
      "φρενῶν  |  φρενῶν\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models: 100%|██████████| 44/44 [00:32<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "καρδίην  |  καρδίην\n",
      "                                                  Text         Entity  \\\n",
      "0            Ἡ δὲ κάτω κοιλία ὁμοία τῇ ὑείᾳ  κάτω κοιλία   \n",
      "1            Ἡ δὲ κάτω κοιλία ὁμοία τῇ ὑείᾳ        ὁμοία   \n",
      "2            Ἡ δὲ κάτω κοιλία ὁμοία τῇ ὑείᾳ        ὑείᾳ   \n",
      "3    Αἱ δ’ ἀρχαὶ τούτων τῶν φλεβῶν, ᾗ σχί...            Αἱ   \n",
      "4    Αἱ δ’ ἀρχαὶ τούτων τῶν φλεβῶν, ᾗ σχί...             δ’   \n",
      "..                                                 ...            ...   \n",
      "268  Ἡπατῖτις ἐν ὀσφύϊ μέχρι τοῦ μεγάλου σ...       ἥπατος   \n",
      "269  Ἡπατῖτις ἐν ὀσφύϊ μέχρι τοῦ μεγάλου σ...           διὰ   \n",
      "270  Ἡπατῖτις ἐν ὀσφύϊ μέχρι τοῦ μεγάλου σ...        φρενῶν   \n",
      "271  Ἡπατῖτις ἐν ὀσφύϊ μέχρι τοῦ μεγάλου σ...            ἐς   \n",
      "272  Ἡπατῖτις ἐν ὀσφύϊ μέχρι τοῦ μεγάλου σ...       καρδίην   \n",
      "\n",
      "               Gold Label         Model 1 Label Model 2 Label Model 3 Label  \\\n",
      "0               Body Part            Topography    Topography    Topography   \n",
      "1    Adjectives/Qualities  Adjectives/Qualities                               \n",
      "2                 Medical  Adjectives/Qualities                  Topography   \n",
      "3                Division                                        Topography   \n",
      "4                Division                                                     \n",
      "..                    ...                   ...           ...           ...   \n",
      "268             Body Part             Body Part     Body Part     Body Part   \n",
      "269            Topography                                        Topography   \n",
      "270             Body Part             Body Part                   Body Part   \n",
      "271            Topography                                                     \n",
      "272             Body Part             Body Part     Body Part     Body Part   \n",
      "\n",
      "                                                Result  \n",
      "0    NER labels are different, Model 1 incorrect (T...  \n",
      "1    NER labels are different, Model 1 correct (Adj...  \n",
      "2    NER labels are different, Model 1 incorrect (A...  \n",
      "3    NER labels are different, Model 1 incorrect ()...  \n",
      "4    NER labels are different, Model 1 incorrect ()...  \n",
      "..                                                 ...  \n",
      "268  All NER labels are the same, Model 1 correct (...  \n",
      "269  NER labels are different, Model 1 incorrect ()...  \n",
      "270  NER labels are different, Model 1 correct (Bod...  \n",
      "271  NER labels are different, Model 1 incorrect ()...  \n",
      "272  All NER labels are the same, Model 1 correct (...  \n",
      "\n",
      "[273 rows x 7 columns]\n",
      "Total same NER labels: 40 (12.78%)\n",
      "Total different NER labels: 273 (87.22%)\n",
      "Model 1 accuracy: 50.16%\n",
      "Model 2 accuracy: 27.48%\n",
      "Model 3 accuracy: 56.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc, DocBin, Span\n",
    "spacy.prefer_gpu()\n",
    "\n",
    "#NER Evaluations:\n",
    "#nlp1 = spacy.load(\"../training/ATLOMY_G_NER_pipeline/sm_10_dec/model-best\")\n",
    "#nlp2 = spacy.load(\"../training/ATLOMY_G_NER_pipeline/sm_3_sep/model-best\")\n",
    "#nlp3 = spacy.load('../training/ATLOMY_G_NER_pipeline/A_GreekBert_sm/model-best')\n",
    "#nlp3 = spacy.load('../training/grc_ud_proiel_trf_Lem_NER/model-best')\n",
    "#nlp3 = spacy.load('../training/ATLOMY_G_NER_pipeline/sm_NFKD_only/model-best')\n",
    "#nlp3 = spacy.load('../training/ATLOMY_G_NER_pipeline/sm_15_sep/model-best')\n",
    "\n",
    "nlp1 = spacy.load('../training/SageMaker/NER/ner_22_dec_trf/model-best')\n",
    "nlp2 = spacy.load('../training/SageMaker/NER/ner_22_dec_vec/model-best')\n",
    "nlp3 = spacy.load('../training/ATLOMY_G_NER_pipeline/sm_15_sep/model-best')\n",
    "\n",
    "\n",
    "evaluator = LemmaEvaluator(nlp1, nlp2, nlp3, norm_method='NFKC')\n",
    "\n",
    "test_docs = DocBin().from_disk('../corpus/test/ner_test/ner_test_NFKC.spacy')\n",
    "docs = list(test_docs.get_docs(nlp1.vocab))\n",
    "\n",
    "df_evaluate_ner = evaluator.evaluate_ner(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP6ChLyYk1pmVs68IB/yCSC",
   "name": "Spacy-TOPO.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "atlomy_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
