{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T11:21:50.281722400Z",
     "start_time": "2023-05-31T11:21:42.414149800Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocess Text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T11:21:50.350623Z",
     "start_time": "2023-05-31T11:21:50.281722400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FILE_PATH = \"../assets/NER_assets/Ancient_Words.csv\"\n",
    "# read csv file\n",
    "df = pd.read_csv(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T13:03:58.601597100Z",
     "start_time": "2023-05-31T13:03:58.573263800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Keyword', 'Word Before', 'Word After', 'Quote', 'Label', 'Lemma',\n",
       "       'Early Category Type', 'Early Word', 'Early Word Before',\n",
       "       'Early Word After', 'Early Quote', 'Lemma arabic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T11:21:50.482203400Z",
     "start_time": "2023-05-31T11:21:50.350623Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rename columns to fit code\n",
    "df.rename(columns = {'Word':'Keyword', 'Category Types':'Label'}, inplace = True)\n",
    "# If a cell is empty (NaN), Fill it with the value in its parallel \"Early\" column\n",
    "for row in df:\n",
    "    df['Quote'].fillna(df['Early Quote'], inplace=True)\n",
    "    df['Word Before'].fillna(df['Early Word Before'], inplace=True)\n",
    "    df['Word After'].fillna(df['Early Word After'], inplace=True)\n",
    "    df['Label'].fillna(df['Early Category Type'], inplace=True)\n",
    "# remove rows with no Keyword\n",
    "df = df.dropna(subset=['Keyword'])\n",
    "# Remove any row that isn't Greek\n",
    "pat = '[ء-ي]+'\n",
    "#df.Keyword.str.contains(pat)\n",
    "df = df[~df.Keyword.str.contains(pat, na=False)]\n",
    "#replace new line in df column\n",
    "df['Keyword'].replace('\\n', '', regex=True, inplace=True)\n",
    "#replace numbers in df\n",
    "df.replace('\\d+', '', regex=True, inplace=True)\n",
    "#replace hyphens in df column\n",
    "df.replace('-', '', regex=True, inplace=True)\n",
    "# replace comma in df column\n",
    "df['Keyword'].replace(',', '', regex=True, inplace=True)\n",
    "#replace period in df column\n",
    "df['Keyword'].replace('\\.', '', regex=True, inplace=True)\n",
    "#replace interpunkt in df column\n",
    "df['Keyword'].replace('\\·', '', regex=True, inplace=True)\n",
    "# replace multiple spaces in df column\n",
    "df.replace(' +', ' ', regex=True, inplace=True)\n",
    "# replace end punctuation in df column\n",
    "df['Keyword'].replace('\\s+$', '', regex=True, inplace=True)\n",
    "\n",
    "df.fillna(0)\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T11:21:50.550994900Z",
     "start_time": "2023-05-31T11:21:50.494339800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Word Before</th>\n",
       "      <th>Word After</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Label</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Early Category Type</th>\n",
       "      <th>Early Word</th>\n",
       "      <th>Early Word Before</th>\n",
       "      <th>Early Word After</th>\n",
       "      <th>Early Quote</th>\n",
       "      <th>Lemma arabic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>οὖλον</td>\n",
       "      <td>δὲ πολυφυὲς</td>\n",
       "      <td>· σάρκινα δὲ</td>\n",
       "      <td>Καὶ τὸ μὲν διφυὲς τοῦ στόματος παρίσθμι...</td>\n",
       "      <td>Body Part</td>\n",
       "      <td>οὖλον</td>\n",
       "      <td>Body Part</td>\n",
       "      <td>οὖλον</td>\n",
       "      <td>δὲ πολυφυὲς</td>\n",
       "      <td>· σάρκινα δὲ</td>\n",
       "      <td>Καὶ τὸ μὲν διφυὲς τοῦ στόματος παρίσθμι...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>παρίσθμιον</td>\n",
       "      <td>τοῦ στόματος</td>\n",
       "      <td>, τὸ δὲ</td>\n",
       "      <td>Καὶ τὸ μὲν διφυὲς τοῦ στόματος παρίσθμι...</td>\n",
       "      <td>Body Part</td>\n",
       "      <td>παρίσθμιον</td>\n",
       "      <td>Body Part</td>\n",
       "      <td>παρίσθμιον</td>\n",
       "      <td>τοῦ στόματος</td>\n",
       "      <td>, τὸ δὲ</td>\n",
       "      <td>Καὶ τὸ μὲν διφυὲς τοῦ στόματος παρίσθμι...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>πολυφυὲς</td>\n",
       "      <td>τὸ δὲ</td>\n",
       "      <td>οὖλον· σάρκινα</td>\n",
       "      <td>Καὶ τὸ μὲν διφυὲς τοῦ στόματος παρίσθμι...</td>\n",
       "      <td>Adjectives/Qualities</td>\n",
       "      <td>πολυφυής</td>\n",
       "      <td>Adjectives/Qualities</td>\n",
       "      <td>πολυφυὲς</td>\n",
       "      <td>τὸ δὲ</td>\n",
       "      <td>οὖλον· σάρκινα</td>\n",
       "      <td>Καὶ τὸ μὲν διφυὲς τοῦ στόματος παρίσθμι...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>μόριον</td>\n",
       "      <td>δ’ ἄλλο</td>\n",
       "      <td>σταφυλοφόρον, κίων</td>\n",
       "      <td>Εἴσω δ’ ἄλλο μόριον σταφυλοφόρον , κίων...</td>\n",
       "      <td>Body Part</td>\n",
       "      <td>μόριον</td>\n",
       "      <td>Body Part</td>\n",
       "      <td>μόριον</td>\n",
       "      <td>δ’ ἄλλο</td>\n",
       "      <td>σταφυλοφόρον, κίων</td>\n",
       "      <td>Εἴσω δ’ ἄλλο μόριον σταφυλοφόρον , κίων...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ὀδόντες</td>\n",
       "      <td>Ἐντὸς δ’</td>\n",
       "      <td>ὀστέινοι. Εἴσω</td>\n",
       "      <td>Ἐντὸς δ’ ὀδόντες ὀστέινοι</td>\n",
       "      <td>Body Part</td>\n",
       "      <td>ὀδούς</td>\n",
       "      <td>Body Part</td>\n",
       "      <td>ὀδόντες</td>\n",
       "      <td>Ἐντὸς δ’</td>\n",
       "      <td>ὀστέινοι. Εἴσω</td>\n",
       "      <td>Ἐντὸς δ’ ὀδόντες ὀστέινοι</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ὀστέινοι</td>\n",
       "      <td>δ’ ὀδόντες</td>\n",
       "      <td>. Εἴσω δ’</td>\n",
       "      <td>Ἐντὸς δ’ ὀδόντες ὀστέινοι</td>\n",
       "      <td>Adjectives/Qualities</td>\n",
       "      <td>ὀστέινος</td>\n",
       "      <td>Adjectives/Qualities</td>\n",
       "      <td>ὀστέινοι</td>\n",
       "      <td>δ’ ὀδόντες</td>\n",
       "      <td>. Εἴσω δ’</td>\n",
       "      <td>Ἐντὸς δ’ ὀδόντες ὀστέινοι</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>σταφυλοφόρον</td>\n",
       "      <td>ἄλλο μόριον</td>\n",
       "      <td>, κίων ἐπίφλεβος·</td>\n",
       "      <td>Εἴσω δ’ ἄλλο μόριον σταφυλοφόρον , κίων...</td>\n",
       "      <td>Adjectives/Qualities</td>\n",
       "      <td>σταφυλοφόρος</td>\n",
       "      <td>Adjectives/Qualities</td>\n",
       "      <td>σταφυλοφόρον</td>\n",
       "      <td>ἄλλο μόριον</td>\n",
       "      <td>, κίων ἐπίφλεβος·</td>\n",
       "      <td>Εἴσω δ’ ἄλλο μόριον σταφυλοφόρον , κίων...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ἐπίφλεβος</td>\n",
       "      <td>σταφυλοφόρον, κίων</td>\n",
       "      <td>· ὃς ἐὰν</td>\n",
       "      <td>Εἴσω δ’ ἄλλο μόριον σταφυλοφόρον, κίων ...</td>\n",
       "      <td>Adjectives/Qualities</td>\n",
       "      <td>ἐπίφλεβος</td>\n",
       "      <td>Adjectives/Qualities</td>\n",
       "      <td>ἐπίφλεβος</td>\n",
       "      <td>σταφυλοφόρον, κίων</td>\n",
       "      <td>· ὃς ἐὰν</td>\n",
       "      <td>Εἴσω δ’ ἄλλο μόριον σταφυλοφόρον, κίων ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>κίων</td>\n",
       "      <td>μόριον σταφυλοφόρον,</td>\n",
       "      <td>ἐπίφλεβος· ὃς</td>\n",
       "      <td>Εἴσω δ’ ἄλλο μόριον σταφυλοφόρον, κίων ...</td>\n",
       "      <td>Adjectives/Qualities</td>\n",
       "      <td>κίων</td>\n",
       "      <td>Adjectives/Qualities</td>\n",
       "      <td>κίων</td>\n",
       "      <td>μόριον σταφυλοφόρον,</td>\n",
       "      <td>ἐπίφλεβος· ὃς</td>\n",
       "      <td>Εἴσω δ’ ἄλλο μόριον σταφυλοφόρον, κίων ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>μέρος</td>\n",
       "      <td>Ἔτι προσώπου</td>\n",
       "      <td>τὸ μὲν</td>\n",
       "      <td>Ἔτι προσώπου μέρος τὸ μὲν ὂν τῷ πνευ...</td>\n",
       "      <td>Adjectives/Qualities</td>\n",
       "      <td>μέρος</td>\n",
       "      <td>Adjectives/Qualities</td>\n",
       "      <td>μέρος</td>\n",
       "      <td>Ἔτι προσώπου</td>\n",
       "      <td>τὸ μὲν</td>\n",
       "      <td>Ἔτι προσώπου μέρος τὸ μὲν ὂν τῷ πνευ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Keyword             Word Before            Word After  \\\n",
       "0         οὖλον           δὲ πολυφυὲς        · σάρκινα δὲ   \n",
       "1    παρίσθμιον          τοῦ στόματος             , τὸ δὲ   \n",
       "2      πολυφυὲς                 τὸ δὲ     οὖλον· σάρκινα   \n",
       "3        μόριον               δ’ ἄλλο  σταφυλοφόρον, κίων   \n",
       "4       ὀδόντες              Ἐντὸς δ’    ὀστέινοι. Εἴσω   \n",
       "5      ὀστέινοι            δ’ ὀδόντες           . Εἴσω δ’   \n",
       "6  σταφυλοφόρον          ἄλλο μόριον  , κίων ἐπίφλεβος·   \n",
       "7     ἐπίφλεβος    σταφυλοφόρον, κίων          · ὃς ἐὰν   \n",
       "8          κίων  μόριον σταφυλοφόρον,     ἐπίφλεβος· ὃς   \n",
       "9         μέρος         Ἔτι προσώπου              τὸ μὲν   \n",
       "\n",
       "                                               Quote                 Label  \\\n",
       "0  Καὶ τὸ μὲν διφυὲς τοῦ στόματος παρίσθμι...             Body Part   \n",
       "1  Καὶ τὸ μὲν διφυὲς τοῦ στόματος παρίσθμι...             Body Part   \n",
       "2  Καὶ τὸ μὲν διφυὲς τοῦ στόματος παρίσθμι...  Adjectives/Qualities   \n",
       "3  Εἴσω δ’ ἄλλο μόριον σταφυλοφόρον , κίων...             Body Part   \n",
       "4                   Ἐντὸς δ’ ὀδόντες ὀστέινοι              Body Part   \n",
       "5                   Ἐντὸς δ’ ὀδόντες ὀστέινοι   Adjectives/Qualities   \n",
       "6  Εἴσω δ’ ἄλλο μόριον σταφυλοφόρον , κίων...  Adjectives/Qualities   \n",
       "7  Εἴσω δ’ ἄλλο μόριον σταφυλοφόρον, κίων ...  Adjectives/Qualities   \n",
       "8  Εἴσω δ’ ἄλλο μόριον σταφυλοφόρον, κίων ...  Adjectives/Qualities   \n",
       "9  Ἔτι προσώπου μέρος τὸ μὲν ὂν τῷ πνευ...  Adjectives/Qualities   \n",
       "\n",
       "           Lemma   Early Category Type    Early Word       Early Word Before  \\\n",
       "0          οὖλον             Body Part         οὖλον           δὲ πολυφυὲς   \n",
       "1     παρίσθμιον             Body Part    παρίσθμιον          τοῦ στόματος   \n",
       "2       πολυφυής  Adjectives/Qualities      πολυφυὲς                 τὸ δὲ   \n",
       "3         μόριον             Body Part        μόριον               δ’ ἄλλο   \n",
       "4          ὀδούς             Body Part       ὀδόντες              Ἐντὸς δ’   \n",
       "5       ὀστέινος  Adjectives/Qualities      ὀστέινοι            δ’ ὀδόντες   \n",
       "6  σταφυλοφόρος   Adjectives/Qualities  σταφυλοφόρον          ἄλλο μόριον   \n",
       "7      ἐπίφλεβος  Adjectives/Qualities     ἐπίφλεβος    σταφυλοφόρον, κίων   \n",
       "8           κίων  Adjectives/Qualities          κίων  μόριον σταφυλοφόρον,   \n",
       "9          μέρος  Adjectives/Qualities         μέρος         Ἔτι προσώπου   \n",
       "\n",
       "       Early Word After                                        Early Quote  \\\n",
       "0        · σάρκινα δὲ  Καὶ τὸ μὲν διφυὲς τοῦ στόματος παρίσθμι...   \n",
       "1             , τὸ δὲ  Καὶ τὸ μὲν διφυὲς τοῦ στόματος παρίσθμι...   \n",
       "2     οὖλον· σάρκινα  Καὶ τὸ μὲν διφυὲς τοῦ στόματος παρίσθμι...   \n",
       "3  σταφυλοφόρον, κίων  Εἴσω δ’ ἄλλο μόριον σταφυλοφόρον , κίων...   \n",
       "4    ὀστέινοι. Εἴσω                   Ἐντὸς δ’ ὀδόντες ὀστέινοι    \n",
       "5           . Εἴσω δ’                   Ἐντὸς δ’ ὀδόντες ὀστέινοι    \n",
       "6  , κίων ἐπίφλεβος·  Εἴσω δ’ ἄλλο μόριον σταφυλοφόρον , κίων...   \n",
       "7          · ὃς ἐὰν  Εἴσω δ’ ἄλλο μόριον σταφυλοφόρον, κίων ...   \n",
       "8     ἐπίφλεβος· ὃς  Εἴσω δ’ ἄλλο μόριον σταφυλοφόρον, κίων ...   \n",
       "9              τὸ μὲν  Ἔτι προσώπου μέρος τὸ μὲν ὂν τῷ πνευ...   \n",
       "\n",
       "  Lemma arabic  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "5          NaN  \n",
       "6          NaN  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T11:21:50.582256500Z",
     "start_time": "2023-05-31T11:21:50.536484300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if any of the fields \"KeyWord\", \"Quote\", \"Word Before\", \"Word After\" are \"0\", drop the row\n",
    "for w in ['Keyword', 'Quote', 'Word Before', 'Word After']:\n",
    "    df = df[df[w] != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T11:21:50.629157200Z",
     "start_time": "2023-05-31T11:21:50.566630700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import requirements for converting the dataframe to Spacy Docs\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "from spacy.tokens import Doc, DocBin\n",
    "from unicodedata import normalize\n",
    "import random\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please notice the above warning about using a deprecated method, and change accordingly.\\\n",
    "<code>FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.</code>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create dictionaries from dendrosearch and conllu files (supplied by Jackobo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T12:37:29.383656200Z",
     "start_time": "2023-05-31T12:37:28.035244800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PUNCTUATION = ['.', \")\", \".\", \"·\", \"(\", \"[\", \"]\", \":\", \";\", \",\", \"?\", \"!\", \"،\", \"_\"]\n",
    "# extract from df a dictionary {word: lemma}\n",
    "lemma_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    lemma_dict[row['Keyword']] = row['Lemma']\n",
    "\n",
    "# load dendrosearch lemma dictionary\n",
    "dendrosearch_lemma_dict = {}\n",
    "with open('../assets/dendrosearch_lemma_dict.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = line.split()\n",
    "        # check if not punctuation\n",
    "        if len(line) > 1 and line[0] not in PUNCTUATION:\n",
    "            dendrosearch_lemma_dict[line[0]] = line[1]\n",
    "\n",
    "# create dictionary from all conllu files\n",
    "PATH = \"../assets/Lemmatization_training_files/\"\n",
    "conllu_lemma_dict = {}\n",
    "\n",
    "# iterate over all files in directory\n",
    "for f in os.listdir(PATH):\n",
    "    if f.endswith(\".conllu\"):\n",
    "        # if file is a conllu file\n",
    "        with open(os.path.join(PATH, f), 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                # conll line is: id | keyword | lemma | pos | _\n",
    "                # we want only keyword and lemma\n",
    "                line = line.split()\n",
    "                if len(line) > 2 and line[1] not in PUNCTUATION:\n",
    "                    conllu_lemma_dict[line[1]] = line[2]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Error fix: I added above the line:\\\n",
    "<code>if f.endswith(\".conllu\")</code>\\\n",
    "Without it it gets an error because it tries to read folders and other files as well.\\ :)\n",
    "2. Why do you add the conllu to dictionary? ANSWER: I thought they might be useful for lemmatization, anyways they can't hurt, and if you don't want them you can just ignore them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create dictionary from INCEpTION files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T13:08:09.090487500Z",
     "start_time": "2023-05-31T13:08:09.044413900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cassis import *\n",
    "import zipfile\n",
    "import tempfile\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "inception_dict = {}\n",
    "inception_sentences = [] # list of tuples (sentence, source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T13:08:10.466843500Z",
     "start_time": "2023-05-31T13:08:09.609063300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roeyz\\AppData\\Local\\Temp\\tmps779gh8g\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n",
      "<cassis.typesystem.TypeSystem object at 0x0000017D7FF7CE50>\n"
     ]
    }
   ],
   "source": [
    "# extract all files in inception folder to temp folder\n",
    "with tempfile.TemporaryDirectory() as tempdir:\n",
    "    for f in os.listdir(\"../assets/NER_assets/INCEpTION_files/\"):\n",
    "        if f.endswith(\".zip\"):\n",
    "            with zipfile.ZipFile(os.path.join(\"../assets/NER_assets/INCEpTION_files/\", f), 'r') as zip_ref:\n",
    "                zip_ref.extractall(tempdir)\n",
    "    print (tempdir)\n",
    "    # open typesystem and print content\n",
    "    with open('{0}/{1}'.format(tempdir, \"TypeSystem.xml\"), 'rb') as f:\n",
    "        typesystem = load_typesystem(f)\n",
    "\n",
    "    # iterate over all files in temp folder\n",
    "    for f in os.listdir(tempdir):\n",
    "        # if file is a xmi file\n",
    "        print (typesystem)\n",
    "        if f.endswith(\".xmi\"):\n",
    "            # load xmi file\n",
    "            with open(os.path.join(tempdir, f), 'rb') as f:\n",
    "                # load typesystem from temp folder\n",
    "                cas = load_cas_from_xmi(f, typesystem=typesystem)\n",
    "                for token in cas.select('de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Lemma'):\n",
    "                    inception_dict[token.get_covered_text()] = token.value\n",
    "                for sentence in cas.select(\"de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence\"):\n",
    "                    # use os to get only file name\n",
    "                    inception_sentences.append((sentence.get_covered_text(), os.path.basename(f.name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T13:08:10.536562200Z",
     "start_time": "2023-05-31T13:08:10.470293800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ἄρθρα 30 \\r\\nτῶν πλευρέων, τὰ μὲν ὄπισθεν τοῦ σώματος πρὸς τοὺς σπονδύλους, τὰ\\r\\nδ᾽ ἔμπροσθεν ἐν τῷ στέρνῳ πρὸς ἑωυτάς.', 'hippocrates places in man 6.1-2.xmi')\n"
     ]
    }
   ],
   "source": [
    "# print random sentence from inception_sentences\n",
    "print (random.choice(inception_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T13:08:10.536987700Z",
     "start_time": "2023-05-31T13:08:10.489014500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create big dict df with word, lemma, source\n",
    "big_dict = {\n",
    "    'Conllu': conllu_lemma_dict,  # files from Jackobo\n",
    "    'Inception': inception_dict,\n",
    "    'Coda': lemma_dict,\n",
    "    'Dendrosearch': dendrosearch_lemma_dict\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T13:08:14.439454400Z",
     "start_time": "2023-05-31T13:08:13.499620400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create two copies of dictionary, one in NFD, other in NFKC\n",
    "\n",
    "# remove all nan values from big_dict\n",
    "# big_dict is a dictionary of dictionaries\n",
    "\n",
    "big_dict = {k: big_dict[k] for k in big_dict if big_dict[k]}\n",
    "big_dict_nfkd = {}\n",
    "big_dict_nfkc = {}\n",
    "\n",
    "for source in big_dict:\n",
    "    big_dict_nfkd[source] = {}\n",
    "    big_dict_nfkc[source] = {}\n",
    "    for word in big_dict[source]:\n",
    "        # if word and lemma are not nan: if\n",
    "        if word and not pd.isnull(word) and big_dict[source][word] and not pd.isnull(big_dict[source][word]):\n",
    "            big_dict_nfkd[source][normalize('NFKD', word)] = normalize('NFD', big_dict[source][word])\n",
    "            big_dict_nfkc[source][normalize('NFKC', word)] = normalize('NFKC', big_dict[source][word])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Notice the error above: TypeError: normalize() argument 2 must be str, not float\n",
    "This is probably due to havving numbers as values in dictionary. NOTE: this in due to nan values in dictionary, anyways there are only 6 of them so I just removed them.\n",
    "2. Why NFD and not NFKD? No reason , you can use NFKD if you want."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Run NLP pipeline on INCEpTION and Coda files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# install spacy grc model if not already installed\n",
    "nlp = spacy.load(\"grc_proiel_sm\") # I use small model for speed but you should use trf (transformer) model for better accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T13:03:11.038655900Z",
     "start_time": "2023-05-31T13:03:11.029039Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge sentences from inception and coda, keep record of source\n",
    "sentences = []\n",
    "for sentence in inception_sentences:\n",
    "    sentences.append((sentence[0], sentence[1]))\n",
    "\n",
    "# add coda sentences(from original df) to sentences list\n",
    "for sentence in df['Quote'].tolist():\n",
    "    sentences.append((sentence, 'Coda'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T13:14:44.396641500Z",
     "start_time": "2023-05-31T13:14:34.012661400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.97it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create list of Doc objects\n",
    "docs_nfkd: List[Doc] = []\n",
    "\n",
    "# create df to record corrections\n",
    "corrections_df_nfkd = pd.DataFrame(columns=['sentence', 'source', 'token', 'lemma', 'lemma_corrected', 'correction_source'])\n",
    "corrected_sentences = 0\n",
    "\n",
    "for sentence in tqdm(sentences):\n",
    "    sentence = (normalize('NFKD', sentence[0]), sentence[1])\n",
    "    doc = nlp(sentence[0])\n",
    "\n",
    "\n",
    "    for token in doc:\n",
    "        for source in big_dict_nfkd: # each source is a dictionary\n",
    "            if token.text in big_dict_nfkd[source]: # if token is in dictionary\n",
    "                if big_dict_nfkd[source][token.text] != token.lemma_: # if lemma is not the same as the one in the dictionary\n",
    "                    corrections_df_nfkd = corrections_df_nfkd.append({\n",
    "                        'sentence': sentence[0],\n",
    "                        'source': sentence[1],\n",
    "                        'token': token.text,\n",
    "                        'lemma': token.lemma_,\n",
    "                        'lemma_corrected': big_dict_nfkd[source][token.text],\n",
    "                        'correction_source': source\n",
    "                    }, ignore_index=True)\n",
    "                    corrected_sentences += 1\n",
    "                    token.lemma_ = big_dict_nfkd[source][token.text]\n",
    "\n",
    "                    break\n",
    "\n",
    "    docs_nfkd.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T13:16:23.596320300Z",
     "start_time": "2023-05-31T13:16:23.540345900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>source</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>lemma_corrected</th>\n",
       "      <th>correction_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>ἡ δ’ ἑτέρη ἄνω τείνει διὰ τῶν φρενῶν ...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>καὶ</td>\n",
       "      <td>καὶ</td>\n",
       "      <td>καί</td>\n",
       "      <td>Conllu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>Ἕτερον δὲ μέρος ἀπὸ τῶν ἀριστερῶν τῆ...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>ἀποσχισθὲν</td>\n",
       "      <td>ἀποσχισθὲν</td>\n",
       "      <td>ἀποσχίζω</td>\n",
       "      <td>Conllu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>Ἔστι δ’ ἡ μὲν ἀρτηρία χονδρώδης τὴν φυ...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>ᾗ</td>\n",
       "      <td>ᾗ</td>\n",
       "      <td>ὅς</td>\n",
       "      <td>Conllu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>πλὴν ἐκείνη μὲν ἡ διὰ τοῦ ἥπατός ἐσ...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>τεινούσης</td>\n",
       "      <td>τεινούσης</td>\n",
       "      <td>εἰς</td>\n",
       "      <td>Coda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>Αἷμα δὲ πλεῖστον μὲν ὁ πλεύμων ἔχει τ...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>πλεῖστον</td>\n",
       "      <td>πλεῖστος</td>\n",
       "      <td>πολύς</td>\n",
       "      <td>Conllu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>Καὶ περὶ ταῦτα τὰ μόρια πολλαὶ ἀπ’ αὐτ...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>πολλαὶ</td>\n",
       "      <td>πολλαὶ</td>\n",
       "      <td>πολύς</td>\n",
       "      <td>Conllu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>Ἀπὸ δὲ κώλου πέφυκεν ἀρχὸς λοίσθιος, σ...</td>\n",
       "      <td>On Anatomy (2).xmi</td>\n",
       "      <td>δακτυλίου</td>\n",
       "      <td>δακτυλίου</td>\n",
       "      <td>δακτύλιος</td>\n",
       "      <td>Conllu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>Καὶ φλέβες δ' ἐς αὐτὸν τείνουσιν ἐξ ἅ...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>δ'</td>\n",
       "      <td>δ'</td>\n",
       "      <td>δέ</td>\n",
       "      <td>Conllu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ἐξ ἅπαντος γὰρ τοῦ σώματος φλέβες ἐς α...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>φλέβες</td>\n",
       "      <td>φλέβες</td>\n",
       "      <td>φλέψ</td>\n",
       "      <td>Conllu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>Εἰς δὲ τὸ ἧπαρ καὶ τὸν σπλῆνα οὐδεμί...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>ἀπὸ</td>\n",
       "      <td>ἀπὸ</td>\n",
       "      <td>ἀπό</td>\n",
       "      <td>Conllu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence              source  \\\n",
       "1226  ἡ δ’ ἑτέρη ἄνω τείνει διὰ τῶν φρενῶν ...                Coda   \n",
       "1515  Ἕτερον δὲ μέρος ἀπὸ τῶν ἀριστερῶν τῆ...                Coda   \n",
       "863   Ἔστι δ’ ἡ μὲν ἀρτηρία χονδρώδης τὴν φυ...                Coda   \n",
       "961   πλὴν ἐκείνη μὲν ἡ διὰ τοῦ ἥπατός ἐσ...                Coda   \n",
       "882   Αἷμα δὲ πλεῖστον μὲν ὁ πλεύμων ἔχει τ...                Coda   \n",
       "1504  Καὶ περὶ ταῦτα τὰ μόρια πολλαὶ ἀπ’ αὐτ...                Coda   \n",
       "1448  Ἀπὸ δὲ κώλου πέφυκεν ἀρχὸς λοίσθιος, σ...  On Anatomy (2).xmi   \n",
       "1800  Καὶ φλέβες δ' ἐς αὐτὸν τείνουσιν ἐξ ἅ...                Coda   \n",
       "5     ἐξ ἅπαντος γὰρ τοῦ σώματος φλέβες ἐς α...                Coda   \n",
       "1616  Εἰς δὲ τὸ ἧπαρ καὶ τὸν σπλῆνα οὐδεμί...                Coda   \n",
       "\n",
       "             token         lemma lemma_corrected correction_source  \n",
       "1226          καὶ          καὶ            καί            Conllu  \n",
       "1515  ἀποσχισθὲν  ἀποσχισθὲν      ἀποσχίζω            Conllu  \n",
       "863           ᾗ          ᾗ            ὅς            Conllu  \n",
       "961     τεινούσης    τεινούσης            εἰς              Coda  \n",
       "882      πλεῖστον     πλεῖστος          πολύς            Conllu  \n",
       "1504       πολλαὶ       πολλαὶ          πολύς            Conllu  \n",
       "1448    δακτυλίου    δακτυλίου      δακτύλιος            Conllu  \n",
       "1800            δ'            δ'             δέ            Conllu  \n",
       "5          φλέβες       φλέβες           φλέψ            Conllu  \n",
       "1616         ἀπὸ         ἀπὸ           ἀπό            Conllu  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter by correction source: Coda Annotation\n",
    "corrections_df_nfkd.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the deprecation warning; I don't get these deprecation warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T13:35:44.874989100Z",
     "start_time": "2023-05-31T13:35:39.170115200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 17.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# create list of Doc objects\n",
    "docs_nfkc: List[Doc] = []\n",
    "\n",
    "# create df to record corrections\n",
    "corrections_df_nfkc = pd.DataFrame(columns=['sentence', 'source', 'token', 'lemma', 'lemma_corrected', 'correction_source'])\n",
    "corrected_sentences = 0\n",
    "\n",
    "\n",
    "for sentence in tqdm(sentences):\n",
    "    sentence = (normalize('NFKC', sentence[0]), sentence[1])\n",
    "    doc = nlp(sentence[0])\n",
    "\n",
    "    # we search train_df for the sentence and add keywords to the doc\n",
    "\n",
    "\n",
    "    for token in doc:\n",
    "        for source in big_dict_nfkc:\n",
    "            if token.text in big_dict_nfkc[source]:\n",
    "                if big_dict_nfkc[source][token.text] != token.lemma_:\n",
    "                    corrections_df_nfkc = corrections_df_nfkc.append({\n",
    "                        'sentence': sentence[0],\n",
    "                        'source': sentence[1],\n",
    "                        'token': token.text,\n",
    "                        'lemma': token.lemma_,\n",
    "                        'lemma_corrected': big_dict_nfkc[source][token.text],\n",
    "                        'correction_source': source\n",
    "                    }, ignore_index=True)\n",
    "                    corrected_sentences += 1\n",
    "                    token.lemma_ = big_dict_nfkc[source][token.text]\n",
    "\n",
    "                    break\n",
    "\n",
    "    docs_nfkc.append(doc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T13:36:05.076054500Z",
     "start_time": "2023-05-31T13:36:05.007497800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>source</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>lemma_corrected</th>\n",
       "      <th>correction_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>Ἐπὶ δὲ θάτερα καθήκει εἰς τὸ μεταξὺ τοῦ πλεύμο...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>δὲ</td>\n",
       "      <td>δέ</td>\n",
       "      <td>δὲ</td>\n",
       "      <td>Dendrosearch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>ἐνίοις μὲν γὰρ εὐρύτερον τὸ πρὸς τῇ κοιλίᾳ, τὸ...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>δὲ</td>\n",
       "      <td>δέ</td>\n",
       "      <td>δὲ</td>\n",
       "      <td>Dendrosearch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>Τούτου δ' αἴτιον ὅτι ἐν μὲν τοῖς ἐξ ἀνάγκης ἔχ...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>αἴτιον</td>\n",
       "      <td>τις</td>\n",
       "      <td>αἴτιος</td>\n",
       "      <td>Conllu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>Ἔστι δ’ ἡ μὲν ἀρτηρία χονδρώδης τὴν φύσιν καὶ ...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>διὰ</td>\n",
       "      <td>διά</td>\n",
       "      <td>διὰ</td>\n",
       "      <td>Inception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>καὶ ἀπὸ μιᾶς δύο ἐστὶ μόρια τῆς ἀρτηρίας, εἰς ...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>δύο</td>\n",
       "      <td>γε</td>\n",
       "      <td>δύο</td>\n",
       "      <td>Conllu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Ἔστι δ’ ἡ ἀορτὴ ἀπὸ μὲν τῆς καρδίας ἀγομένη εὖ...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>ἐπιστενοτέρα</td>\n",
       "      <td>ἐπιστενοτέρα</td>\n",
       "      <td>ἐπίστενος</td>\n",
       "      <td>Coda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>ἡ δ’ ἑτέρη ἄνω τείνει διὰ τῶν φρενῶν καὶ τοῦ π...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>φρενῶν</td>\n",
       "      <td>φρενή</td>\n",
       "      <td>φρήν</td>\n",
       "      <td>Conllu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>Εἶτ' ἐντεῦθεν πάλιν, ὥσπερ ἀπὸ τῆς ἄνω κοιλίας...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>ἕλικα</td>\n",
       "      <td>ἕλιξ</td>\n",
       "      <td>ἕλιξ</td>\n",
       "      <td>Coda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>Ἔστι δ’ ἡ μὲν ἀρτηρία χονδρώδης τὴν φύσιν καὶ ...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>κατὰ</td>\n",
       "      <td>κατά</td>\n",
       "      <td>κατὰ</td>\n",
       "      <td>Inception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>διότι οὐκ αἰεὶ κατὰ τωὐτὸ τῆς κεφαλὴς ἀλγεῖ, ἀ...</td>\n",
       "      <td>Coda</td>\n",
       "      <td>δὲ</td>\n",
       "      <td>δέ</td>\n",
       "      <td>δὲ</td>\n",
       "      <td>Dendrosearch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence source         token  \\\n",
       "574  Ἐπὶ δὲ θάτερα καθήκει εἰς τὸ μεταξὺ τοῦ πλεύμο...   Coda            δὲ   \n",
       "226  ἐνίοις μὲν γὰρ εὐρύτερον τὸ πρὸς τῇ κοιλίᾳ, τὸ...   Coda            δὲ   \n",
       "384  Τούτου δ' αἴτιον ὅτι ἐν μὲν τοῖς ἐξ ἀνάγκης ἔχ...   Coda        αἴτιον   \n",
       "531  Ἔστι δ’ ἡ μὲν ἀρτηρία χονδρώδης τὴν φύσιν καὶ ...   Coda           διὰ   \n",
       "317  καὶ ἀπὸ μιᾶς δύο ἐστὶ μόρια τῆς ἀρτηρίας, εἰς ...   Coda           δύο   \n",
       "314  Ἔστι δ’ ἡ ἀορτὴ ἀπὸ μὲν τῆς καρδίας ἀγομένη εὖ...   Coda  ἐπιστενοτέρα   \n",
       "327  ἡ δ’ ἑτέρη ἄνω τείνει διὰ τῶν φρενῶν καὶ τοῦ π...   Coda        φρενῶν   \n",
       "443  Εἶτ' ἐντεῦθεν πάλιν, ὥσπερ ἀπὸ τῆς ἄνω κοιλίας...   Coda         ἕλικα   \n",
       "602  Ἔστι δ’ ἡ μὲν ἀρτηρία χονδρώδης τὴν φύσιν καὶ ...   Coda          κατὰ   \n",
       "260  διότι οὐκ αἰεὶ κατὰ τωὐτὸ τῆς κεφαλὴς ἀλγεῖ, ἀ...   Coda            δὲ   \n",
       "\n",
       "            lemma lemma_corrected correction_source  \n",
       "574            δέ              δὲ      Dendrosearch  \n",
       "226            δέ              δὲ      Dendrosearch  \n",
       "384           τις          αἴτιος            Conllu  \n",
       "531           διά             διὰ         Inception  \n",
       "317            γε             δύο            Conllu  \n",
       "314  ἐπιστενοτέρα       ἐπίστενος              Coda  \n",
       "327         φρενή            φρήν            Conllu  \n",
       "443          ἕλιξ           ἕλιξ               Coda  \n",
       "602          κατά            κατὰ         Inception  \n",
       "260            δέ              δὲ      Dendrosearch  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrections_df_nfkc.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T13:36:26.518066900Z",
     "start_time": "2023-05-31T13:36:26.450786900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>source</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>lemma_corrected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correction_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Coda</th>\n",
       "      <td>307</td>\n",
       "      <td>307</td>\n",
       "      <td>307</td>\n",
       "      <td>307</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conllu</th>\n",
       "      <td>1562</td>\n",
       "      <td>1562</td>\n",
       "      <td>1562</td>\n",
       "      <td>1562</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dendrosearch</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inception</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sentence  source  token  lemma  lemma_corrected\n",
       "correction_source                                                 \n",
       "Coda                    307     307    307    307              307\n",
       "Conllu                 1562    1562   1562   1562             1562\n",
       "Dendrosearch             34      34     34     34               34\n",
       "Inception                 5       5      5      5                5"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find how many corrected by each dictionary\n",
    "corrections_df_nfkd.groupby('correction_source').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T13:36:31.590109100Z",
     "start_time": "2023-05-31T13:36:31.501185500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>source</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>lemma_corrected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correction_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Coda</th>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conllu</th>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dendrosearch</th>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inception</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sentence  source  token  lemma  lemma_corrected\n",
       "correction_source                                                 \n",
       "Coda                    291     291    291    291              291\n",
       "Conllu                  155     155    155    155              155\n",
       "Dendrosearch            110     110    110    110              110\n",
       "Inception                69      69     69     69               69"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrections_df_nfkc.groupby('correction_source').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-25T09:16:56.014284100Z",
     "start_time": "2023-05-25T09:16:55.612462500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_docs size: 739\n",
      "dev_docs size: 493\n",
      "test_docs size: 308\n"
     ]
    }
   ],
   "source": [
    "# split docs to train, dev, test randomly\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "\n",
    "# split docs to train, dev, test randomly, for each normalization\n",
    "\n",
    "train_docs_nfkd, test_docs_nfkd = train_test_split(docs_nfkd, test_size=0.2, random_state=42)\n",
    "train_docs_nfkd, dev_docs_nfkd = train_test_split(train_docs_nfkd, test_size=0.2, random_state=42)\n",
    "\n",
    "train_docs_nfkc, test_docs_nfkc = train_test_split(docs_nfkc, test_size=0.2, random_state=42)\n",
    "train_docs_nfkc, dev_docs_nfkc = train_test_split(train_docs_nfkc, test_size=0.2, random_state=42)\n",
    "\n",
    "print (f\"train: {len(train_docs_nfkd)}\\ndev: {len(dev_docs_nfkd)}\\ntest: {len(test_docs_nfkd)} for nfkd\")\n",
    "print (f\"train: {len(train_docs_nfkc)}\\ndev: {len(dev_docs_nfkc)}\\ntest: {len(test_docs_nfkc)} for nfkc\")\n",
    "# save each one to DocBin\n",
    "\n",
    "Path(\"../corpus/train\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"../corpus/dev\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"../corpus/test\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "train_bin_nfkd = DocBin(docs=train_docs_nfkd)\n",
    "train_bin_nfkd.to_disk(\"../corpus/train/train_lemma__nfkd.spacy\")\n",
    "test_bin_nfkd = DocBin(docs=test_docs_nfkd)\n",
    "test_bin_nfkd.to_disk(\"../corpus/test/test_lemma__nfkd.spacy\")\n",
    "dev_bin_nfkd = DocBin(docs=dev_docs_nfkd)\n",
    "dev_bin_nfkd.to_disk(\"../corpus/dev/dev_lemma__nfkd.spacy\")\n",
    "\n",
    "train_bin_nfkc = DocBin(docs=train_docs_nfkc)\n",
    "train_bin_nfkc.to_disk(\"../corpus/train/train_lemma__nfkc.spacy\")\n",
    "test_bin_nfkc = DocBin(docs=test_docs_nfkc)\n",
    "test_bin_nfkc.to_disk(\"../corpus/test/test_lemma__nfkc.spacy\")\n",
    "dev_bin_nfkc = DocBin(docs=dev_docs_nfkc)\n",
    "dev_bin_nfkc.to_disk(\"../corpus/dev/dev_lemma__nfkc.spacy\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spacy dataset should be exported to '../corpus/' folder.\\\n",
    "More specifically:\\\n",
    "train to '..corpus/train/lemma_train/'\\\n",
    "dev to '../corpus/dev/lemma_dev/'\\\n",
    "test to '../corpus/test/lemma_test/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
