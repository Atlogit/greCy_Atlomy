{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"tlgu -b -c utf-8 ../assets/beta_files/TLG0563.TXT ../assets/beta_files/output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Α/β(γδΕΦΓΗΙΚΛΜΝΟΠΘΡΣΤΥϜΩΧΨΦ'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample beta code text (a short segment for demonstration)\n",
    "# This will be replaced with the actual content from the file in the final implementation\n",
    "beta_code_sample = \"*A/B(GD*E*F*G*H*I*K*L*M*N*O*P*Q*R*S*T*U*V*W*X*Y*Z\"\n",
    "\n",
    "# Mapping of Greek beta code to Unicode characters\n",
    "# This is a simplified version based on the provided manual; it can be expanded for full coverage\n",
    "beta_to_unicode = {\n",
    "    \"*A\": \"\\u0391\", \"A\": \"\\u03B1\",  # Alpha\n",
    "    \"*B\": \"\\u0392\", \"B\": \"\\u03B2\",  # Beta\n",
    "    \"*C\": \"\\u039E\", \"C\": \"\\u03BE\",  # Xi\n",
    "    \"*D\": \"\\u0394\", \"D\": \"\\u03B4\",  # Delta\n",
    "    \"*E\": \"\\u0395\", \"E\": \"\\u03B5\",  # Epsilon\n",
    "    \"*F\": \"\\u03A6\", \"F\": \"\\u03C6\",  # Phi\n",
    "    \"*G\": \"\\u0393\", \"G\": \"\\u03B3\",  # Gamma\n",
    "    \"*H\": \"\\u0397\", \"H\": \"\\u03B7\",  # Eta\n",
    "    \"*I\": \"\\u0399\", \"I\": \"\\u03B9\",  # Iota\n",
    "    \"*K\": \"\\u039A\", \"K\": \"\\u03BA\",  # Kappa\n",
    "    \"*L\": \"\\u039B\", \"L\": \"\\u03BB\",  # Lambda\n",
    "    \"*M\": \"\\u039C\", \"M\": \"\\u03BC\",  # Mu\n",
    "    \"*N\": \"\\u039D\", \"N\": \"\\u03BD\",  # Nu\n",
    "    \"*O\": \"\\u039F\", \"O\": \"\\u03BF\",  # Omicron\n",
    "    \"*P\": \"\\u03A0\", \"P\": \"\\u03C0\",  # Pi\n",
    "    \"*Q\": \"\\u0398\", \"Q\": \"\\u03B8\",  # Theta\n",
    "    \"*R\": \"\\u03A1\", \"R\": \"\\u03C1\",  # Rho\n",
    "    \"*S\": \"\\u03A3\", \"S\": \"\\u03C3\",  # Sigma\n",
    "    \"*T\": \"\\u03A4\", \"T\": \"\\u03C4\",  # Tau\n",
    "    \"*U\": \"\\u03A5\", \"U\": \"\\u03C5\",  # Upsilon\n",
    "    \"*V\": \"\\u03DC\", \"V\": \"\\u03DD\",  # Digamma\n",
    "    \"*W\": \"\\u03A9\", \"W\": \"\\u03C9\",  # Omega\n",
    "    \"*X\": \"\\u03A7\", \"X\": \"\\u03C7\",  # Chi\n",
    "    \"*Y\": \"\\u03A8\", \"Y\": \"\\u03C8\",  # Psi\n",
    "    \"*Z\": \"\\u03A6\", \"Z\": \"\\u03B6\",  # Zeta\n",
    "    # Add diacritics and other characters as needed\n",
    "}\n",
    "\n",
    "# Function to convert beta code to Unicode\n",
    "def beta_code_to_unicode(beta_text, mapping):\n",
    "    # Sort the keys by length in descending order to replace longer sequences first\n",
    "    sorted_keys = sorted(mapping, key=len, reverse=True)\n",
    "    for key in sorted_keys:\n",
    "        beta_text = beta_text.replace(key, mapping[key])\n",
    "    return beta_text\n",
    "\n",
    "# Convert the sample beta code text to Unicode\n",
    "decoded_text = beta_code_to_unicode(beta_code_sample, beta_to_unicode)\n",
    "decoded_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<author>>0001<<work>>001<<abbreviation>>Arg\\n<author>\"0001\"<work>\"001\"<abbreviation>\"αrg\"\\nΑ/β(γδΕΦΓΗΙΚΛΜΝΟΠΘΡΣΤΥϜΩΧΨΦ'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expanding the script to handle citations and reserved escape codes based on the new information provided\n",
    "\n",
    "# Append the new knowledge about citation system to the existing beta to unicode mapping\n",
    "beta_to_unicode.update({\n",
    "    # Assuming some example mappings for citation and escape codes (to be replaced with actual mappings)\n",
    "    \"~a\": \"<author>\", \"~b\": \"<work>\", \"~c\": \"<abbreviation>\",\n",
    "    \"~n\": \"<non-hierarchical-citation>\", \"~v\": \"<hierarchical-field-v>\",\n",
    "    \"~z\": \"<line-number>\",  # and so on for other fields\n",
    "    # Add more mappings for reserved escapes and additional characters\n",
    "    \"$50\": \"<reserved-papyri-1>\", \"$59\": \"<reserved-papyri-10>\",  # and so on\n",
    "    \"&50\": \"<reserved-latin-1>\", \"&59\": \"<reserved-latin-10>\",  # and so on\n",
    "    # More mappings as needed\n",
    "})\n",
    "\n",
    "# Function to increment values for implicit citation changes\n",
    "def increment_value(value):\n",
    "    if value.isdigit():\n",
    "        return str(int(value) + 1)\n",
    "    else:\n",
    "        # Incrementing the ASCII character\n",
    "        return chr(ord(value[-1]) + 1)\n",
    "\n",
    "# Updated function to handle citations and implicit value changes\n",
    "def decode_beta_code(beta_text, mapping):\n",
    "    # Split the text into lines for processing citations\n",
    "    lines = beta_text.splitlines()\n",
    "    decoded_lines = []\n",
    "    last_citation = {}\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"~\"):\n",
    "            # Process citation line\n",
    "            citation_parts = re.findall(r'~[a-z]\"?([^\"]*)\"?', line)\n",
    "            for i, part in enumerate(citation_parts):\n",
    "                field = chr(ord('a') + i)  # Calculate field identifier ('a', 'b', 'c', ...)\n",
    "                if part:\n",
    "                    # Explicit change in citation\n",
    "                    last_citation[field] = part\n",
    "                else:\n",
    "                    # Implicit change (increment)\n",
    "                    last_citation[field] = increment_value(last_citation.get(field, \"1\"))\n",
    "            # Construct the citation string (e.g., \"<author>1<work>2<line-number>3\")\n",
    "            citation_string = \"\".join([f\"<{mapping.get('~' + k, '')}>{v}\" for k, v in last_citation.items()])\n",
    "            decoded_lines.append(citation_string)\n",
    "        else:\n",
    "            # Regular text line\n",
    "            decoded_line = beta_text\n",
    "            for key in sorted(mapping, key=len, reverse=True):\n",
    "                decoded_line = decoded_line.replace(key, mapping[key])\n",
    "            decoded_lines.append(decoded_line)\n",
    "\n",
    "    return \"\\n\".join(decoded_lines)\n",
    "\n",
    "# Sample text including citations (to be replaced with actual file content)\n",
    "sample_text_with_citations = \"~a\\\"0001\\\"~b\\\"001\\\"~c\\\"Arg\\\"\\n*A/B(GD*E*F*G*H*I*K*L*M*N*O*P*Q*R*S*T*U*V*W*X*Y*Z\"\n",
    "\n",
    "# Decode the sample text\n",
    "decoded_text_with_citations = decode_beta_code(sample_text_with_citations, beta_to_unicode)\n",
    "decoded_text_with_citations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<combining-overline>page-end>Α/β(γδΕΦΓ<combining-overline>start-of-table>ηΙΚΛΜ<combining-overline>end-of-table>νΟΠΘΡΣΤΥϜΩΧΨΦ<combining-overline>page-end>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expanding the script to include formatting beta codes\n",
    "\n",
    "# Update the beta to unicode mapping with formatting codes\n",
    "beta_to_unicode.update({\n",
    "    \"^\": \"<quarter-space>\",\n",
    "    \"@\": \"<tab>\",\n",
    "    \"@1\": \"<page-end>\",\n",
    "    \"@2\": \"<column-end>\",\n",
    "    \"@3\": \"<omitted-graphic>\",\n",
    "    \"@4\": \"<start-of-table>\",\n",
    "    \"@5\": \"<end-of-table>\",\n",
    "    \"@6\": \"<blank-line>\",\n",
    "    \"@7\": \"<short-horizontal-rule>\",\n",
    "    \"@8\": \"<mid-line-citation>\",\n",
    "    \"@9\": \"<break-in-text>\",\n",
    "    # Add more mappings as needed\n",
    "    \"{\": \"<speaker-stage-direction>\",\n",
    "    \"{1\": \"<title>\",\n",
    "    \"{2\": \"<marginal-text>\",\n",
    "    # ... and so on for other text formatting codes\n",
    "    \"<\": \"<combining-overline>\", # And other text formatting symbols\n",
    "    # ... and so on for other text formatting codes\n",
    "    # Quotation marks and other additional punctuation and characters\n",
    "    \"\\\"\": \"<left-double-quotation-mark>\",\n",
    "    \"\\\"1\": \"<left-low-double-quotation-mark>\",\n",
    "    # ... and so on\n",
    "})\n",
    "\n",
    "# We'll also need to handle the brackets, but these are placeholders for now\n",
    "beta_to_unicode.update({\n",
    "    \"[\": \"<left-square-bracket>\",\n",
    "    \"]\": \"<right-square-bracket>\",\n",
    "    # ... and so on for other brackets\n",
    "})\n",
    "\n",
    "# The updated function now includes handling for formatting beta codes\n",
    "def decode_beta_code_with_formatting(beta_text, mapping):\n",
    "    decoded_text = beta_text\n",
    "    for key in sorted(mapping, key=len, reverse=True):\n",
    "        decoded_text = decoded_text.replace(key, mapping[key])\n",
    "    return decoded_text\n",
    "\n",
    "# Sample text including formatting codes (to be replaced with actual file content)\n",
    "sample_text_with_formatting = \"@1*A/B(GD*E*F*G@4H*I*K*L*M@5N*O*P*Q*R*S*T*U*V*W*X*Y*Z@1\"\n",
    "\n",
    "# Decode the sample text\n",
    "decoded_text_with_formatting = decode_beta_code_with_formatting(sample_text_with_formatting, beta_to_unicode)\n",
    "decoded_text_with_formatting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_beta_code_with_formatting(../assets/beta_files/TLG0563.TXT ../assets/beta_files/output.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "def process_file(input_file_path, output_file_path, mapping):\n",
    "    # Detect the encoding of the file\n",
    "    with open('../assets/beta_files/TLG0563.TXT', 'rb') as file:\n",
    "        result = chardet.detect(file.read())\n",
    "\n",
    "    # Open the file with the detected encoding\n",
    "    with open('../assets/beta_files/TLG0563.TXT', 'r', encoding=result['encoding']) as file:\n",
    "        lines = file.read()\n",
    "\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "        for line in lines:\n",
    "            # Apply the conversion to each line\n",
    "            decoded_line = decode_beta_code_with_formatting(line, mapping)\n",
    "            output_file.write(decoded_line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths\n",
    "input_file_path = '../assets/beta_files/TLG0563.TXT'  # Replace with the path to your file\n",
    "output_file_path = '../assets/beta_files/output.txt'  # Replace with the path to your output file\n",
    "\n",
    "# Process the entire file\n",
    "process_file(input_file_path, output_file_path, beta_to_unicode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'beta_to_uni' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     data \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Convert Beta Code to Unicode\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m unicode_text \u001b[38;5;241m=\u001b[39m beta_to_uni(beta_code)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(unicode_text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'beta_to_uni' is not defined"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "\n",
    "# Detect the encoding of the file\n",
    "with open('../assets/beta_files/TLG0563.TXT', 'rb') as file:\n",
    "    result = chardet.detect(file.read())\n",
    "\n",
    "# Open the file with the detected encoding\n",
    "with open('../assets/beta_files/TLG0563.TXT', 'r', encoding=result['encoding']) as file:\n",
    "    data = file.read()\n",
    "    \n",
    "# Convert Beta Code to Unicode\n",
    "unicode_text = beta_to_uni(beta_code)\n",
    "\n",
    "print(unicode_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'MacRoman', 'confidence': 0.643100264793705, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlomy_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
